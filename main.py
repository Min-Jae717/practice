import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import json
import numpy as np
from typing import TypedDict, Annotated, List, Dict, Optional
import operator

# ì„¤ì • íŒŒì¼ import
from config import get_app_config, check_secrets

# Streamlit í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ë²ˆì§¸ë¡œ ìœ„ì¹˜)
st.set_page_config(
    page_title="ğŸš€ AI ì…ì°° ê³µê³  í†µí•© í”Œë«í¼", 
    layout="wide",
    initial_sidebar_state="collapsed",
    page_icon="ğŸš€"
)

# ê³ ê¸‰ CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    /* ë©”ì¸ í—¤ë” ìŠ¤íƒ€ì¼ */
    .main-header {
        text-align: center;
        padding: 3rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        color: white;
        border-radius: 20px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        position: relative;
        overflow: hidden;
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: rotate 20s linear infinite;
    }
    
    .main-header h1 {
        font-size: 3.5rem;
        font-weight: 900;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        position: relative;
        z-index: 1;
        margin-bottom: 1rem;
    }
    
    .main-header p {
        font-size: 1.4rem;
        opacity: 0.95;
        line-height: 1.6;
        position: relative;
        z-index: 1;
    }
    
    @keyframes rotate {
        from { transform: rotate(0deg); }
        to { transform: rotate(360deg); }
    }
    
    /* ê³ ê¸‰ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .advanced-card {
        background: linear-gradient(145deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border: 1px solid rgba(255,255,255,0.2);
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .advanced-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 35px rgba(0,0,0,0.15);
    }
    
    /* ìœ ì‚¬ë„ ìŠ¤íƒ€ì¼ */
    .similarity-high { 
        color: #28a745; 
        font-weight: bold; 
        background: linear-gradient(45deg, #28a745, #20c997);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .similarity-medium { 
        color: #ffc107; 
        font-weight: bold;
        background: linear-gradient(45deg, #ffc107, #fd7e14);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .similarity-low { 
        color: #dc3545;
        background: linear-gradient(45deg, #dc3545, #e83e8c);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    /* ì›Œí¬í”Œë¡œìš° ìŠ¤í… ìŠ¤íƒ€ì¼ */
    .workflow-step {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 12px 16px;
        margin: 8px 0;
        border-left: 4px solid #007bff;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        animation: slideIn 0.3s ease-out;
    }
    
    .workflow-success {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
        border-left-color: #28a745;
    }
    
    .workflow-warning {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        border-left-color: #ffc107;
    }
    
    .workflow-error {
        background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);
        border-left-color: #dc3545;
    }
    
    @keyframes slideIn {
        from { opacity: 0; transform: translateX(-10px); }
        to { opacity: 1; transform: translateX(0); }
    }
    
    /* í†µê³„ ì¹´ë“œ */
    .stats-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3);
    }
    
    .stats-number {
        font-size: 2.5rem;
        font-weight: 900;
        margin-bottom: 0.5rem;
    }
    
    .stats-label {
        font-size: 1rem;
        opacity: 0.9;
    }
    
    /* ê²€ìƒ‰ ê²°ê³¼ ì¹´ë“œ */
    .result-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 0.8rem 0;
        border: 1px solid #e9ecef;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        transition: all 0.3s ease;
    }
    
    .result-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.12);
        border-color: #007bff;
    }
</style>
""", unsafe_allow_html=True)

# LangGraph ìƒíƒœ ì •ì˜
class BidSearchState(TypedDict):
    """ì…ì°° ê³µê³  ê²€ìƒ‰ ìƒíƒœ"""
    query: str
    keyword_results: List[Dict]
    semantic_results: List[Dict]
    api_results: List[Dict]
    combined_results: List[Dict]
    final_answer: str
    messages: Annotated[List[str], operator.add]
    error: Optional[str]
    statistics: Dict[str, int]

# ê³ ê¸‰ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í´ë˜ìŠ¤
class AdvancedBidManager:
    def __init__(self):
        try:
            import psycopg2
            from psycopg2.extras import RealDictCursor
            
            config = get_app_config()
            self.connection = psycopg2.connect(
                config.database.url,
                cursor_factory=RealDictCursor
            )
            self.connection.autocommit = True
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.connection = None
    
    def get_live_bids(self, limit=50, filters=None):
        """ì‹¤ì‹œê°„ ì…ì°° ê³µê³  ì¡°íšŒ (ê³ ê¸‰ í•„í„°ë§)"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            
            # ê¸°ë³¸ ì¿¼ë¦¬
            base_query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw->>'bidNtceDate' as bidNtceDate,
                raw->>'bidClseDate' as bidClseDate,
                raw->>'bidNtceSttusNm' as bidNtceSttusNm,
                raw
            FROM bids_live
            WHERE 1=1
            """
            
            params = []
            
            # í•„í„° ì ìš©
            if filters:
                if filters.get('categories'):
                    base_query += " AND raw->>'bsnsDivNm' = ANY(%s)"
                    params.append(filters['categories'])
                
                if filters.get('min_amount'):
                    base_query += " AND CAST(raw->>'asignBdgtAmt' AS BIGINT) >= %s"
                    params.append(filters['min_amount'])
                
                if filters.get('max_amount'):
                    base_query += " AND CAST(raw->>'asignBdgtAmt' AS BIGINT) <= %s"
                    params.append(filters['max_amount'])
                
                if filters.get('date_from'):
                    base_query += " AND raw->>'bidNtceDate' >= %s"
                    params.append(filters['date_from'])
                
                if filters.get('date_to'):
                    base_query += " AND raw->>'bidNtceDate' <= %s"
                    params.append(filters['date_to'])
            
            base_query += " ORDER BY created_at DESC LIMIT %s"
            params.append(limit)
            
            cursor.execute(base_query, params)
            results = cursor.fetchall()
            return [dict(row) for row in results]
            
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def get_statistics(self):
        """ì…ì°° ê³µê³  í†µê³„ ì¡°íšŒ"""
        if not self.connection:
            return {}
        
        try:
            cursor = self.connection.cursor()
            
            # ì „ì²´ í†µê³„
            stats_query = """
            SELECT 
                COUNT(*) as total_bids,
                COUNT(CASE WHEN raw->>'bidNtceSttusNm' = 'ê³µê³ ì¤‘' THEN 1 END) as active_bids,
                COUNT(DISTINCT raw->>'ntceInsttNm') as unique_orgs,
                AVG(CAST(raw->>'asignBdgtAmt' AS BIGINT)) as avg_amount
            FROM bids_live
            """
            
            cursor.execute(stats_query)
            stats = cursor.fetchone()
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            category_query = """
            SELECT 
                raw->>'bsnsDivNm' as category,
                COUNT(*) as count
            FROM bids_live
            GROUP BY raw->>'bsnsDivNm'
            ORDER BY count DESC
            """
            
            cursor.execute(category_query)
            categories = cursor.fetchall()
            
            return {
                'total_bids': stats['total_bids'] or 0,
                'active_bids': stats['active_bids'] or 0,
                'unique_orgs': stats['unique_orgs'] or 0,
                'avg_amount': stats['avg_amount'] or 0,
                'categories': [dict(row) for row in categories]
            }
            
        except Exception as e:
            return {
                'total_bids': 0,
                'active_bids': 0,
                'unique_orgs': 0,
                'avg_amount': 0,
                'categories': []
            }
    
    def search_bids(self, keyword, advanced_filters=None):
        """ê³ ê¸‰ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            
            # ì „ë¬¸ ê²€ìƒ‰ í™œìš©
            query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw,
                ts_rank(
                    to_tsvector('simple', 
                        COALESCE(raw->>'bidNtceNm', '') || ' ' ||
                        COALESCE(raw->>'ntceInsttNm', '') || ' ' ||
                        COALESCE(raw->>'bidprcPsblIndstrytyNm', '')
                    ),
                    plainto_tsquery('simple', %s)
                ) as rank
            FROM bids_live
            WHERE to_tsvector('simple', 
                COALESCE(raw->>'bidNtceNm', '') || ' ' ||
                COALESCE(raw->>'ntceInsttNm', '') || ' ' ||
                COALESCE(raw->>'bidprcPsblIndstrytyNm', '')
            ) @@ plainto_tsquery('simple', %s)
            ORDER BY rank DESC, created_at DESC
            LIMIT 50
            """
            
            cursor.execute(query, (keyword, keyword))
            results = cursor.fetchall()
            return [dict(row) for row in results]
            
        except Exception as e:
            # í´ë°±: ê¸°ë³¸ ILIKE ê²€ìƒ‰
            cursor = self.connection.cursor()
            fallback_query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw
            FROM bids_live
            WHERE raw->>'bidNtceNm' ILIKE %s
               OR raw->>'ntceInsttNm' ILIKE %s
               OR raw->>'bidprcPsblIndstrytyNm' ILIKE %s
            ORDER BY created_at DESC
            LIMIT 30
            """
            cursor.execute(fallback_query, (f"%{keyword}%", f"%{keyword}%", f"%{keyword}%"))
            results = cursor.fetchall()
            return [dict(row) for row in results]

# ê³ ê¸‰ ë²¡í„° ê²€ìƒ‰ í´ë˜ìŠ¤
class AdvancedVectorEngine:
    def __init__(self):
        try:
            from sentence_transformers import SentenceTransformer
            self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            self.is_loaded = True
        except Exception as e:
            st.warning(f"ë²¡í„° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.is_loaded = False
    
    def encode_text(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        if not self.is_loaded:
            return None
        try:
            return self.model.encode([text])[0]
        except Exception as e:
            return None
    
    def semantic_search_with_explanation(self, query, bid_data, top_k=10, explain=False):
        """ì„¤ëª… ê°€ëŠ¥í•œ ì‹œë§¨í‹± ê²€ìƒ‰"""
        if not self.is_loaded or not bid_data:
            return []
        
        try:
            from sklearn.metrics.pairwise import cosine_similarity
            
            # ì¿¼ë¦¬ ë²¡í„°í™”
            query_vector = self.encode_text(query)
            if query_vector is None:
                return []
            
            # ë¬¸ì„œ ë²¡í„°í™” ë° í‚¤ì›Œë“œ ë§¤ì¹­
            results = []
            
            for bid in bid_data:
                # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ êµ¬ì„±
                title = bid.get('bidNtceNm', '') or bid.get('bidntcenm', '')
                org = bid.get('ntceInsttNm', '') or bid.get('ntceinsttm', '')
                category = bid.get('bsnsDivNm', '') or bid.get('bsnsdivnm', '')
                
                text = f"{title} {org} {category}"
                doc_vector = self.encode_text(text)
                
                if doc_vector is not None:
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = cosine_similarity([query_vector], [doc_vector])[0][0]
                    
                    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                    keyword_score = 0
                    query_words = query.lower().split()
                    for word in query_words:
                        if word in text.lower():
                            keyword_score += 1
                    
                    # ë³µí•© ì ìˆ˜ ê³„ì‚°
                    final_score = similarity * 0.7 + (keyword_score / len(query_words)) * 0.3
                    
                    if final_score > 0.1:
                        result = {
                            'document': bid,
                            'similarity': float(similarity),
                            'keyword_score': keyword_score,
                            'final_score': float(final_score),
                            'explanation': {
                                'matched_terms': [w for w in query_words if w in text.lower()],
                                'semantic_similarity': float(similarity),
                                'keyword_matches': keyword_score
                            }
                        }
                        results.append(result)
            
            # ìµœì¢… ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)
            return results[:top_k]
            
        except Exception as e:
            st.error(f"ê³ ê¸‰ ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ê³ ê¸‰ API ê²€ìƒ‰ í´ë˜ìŠ¤
class AdvancedAPIEngine:
    def __init__(self):
        try:
            config = get_app_config()
            self.service_key = config.api.service_key
            self.base_url = config.api.base_url
            self.endpoints = {
                "ìš©ì—­": f"{self.base_url}/getBidPblancListInfoServc",
                "ë¬¼í’ˆ": f"{self.base_url}/getBidPblancListInfoThng",
                "ê³µì‚¬": f"{self.base_url}/getBidPblancListInfoCnstwk"
            }
        except Exception as e:
            self.service_key = None
    
    def search_with_retry(self, query, max_retries=2):
        """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” API ê²€ìƒ‰"""
        if not self.service_key:
            return []
        
        import requests
        from urllib.parse import urlencode
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)
        
        all_results = []
        
        for category, endpoint in self.endpoints.items():
            for attempt in range(max_retries + 1):
                try:
                    params = {
                        'serviceKey': self.service_key,
                        'pageNo': 1,
                        'numOfRows': 15,
                        'type': 'json',
                        'inqryBgnDt': start_date.strftime('%Y%m%d') + '0000',
                        'inqryEndDt': end_date.strftime('%Y%m%d') + '2359',
                        'bidNtceNm': query
                    }
                    
                    response = requests.get(endpoint, params=params, timeout=15)
                    
                    if response.status_code == 200:
                        data = response.json()
                        items = data.get('response', {}).get('body', {}).get('items', [])
                        
                        if items:
                            for item in items:
                                item['source'] = f'ì‹¤ì‹œê°„API({category})'
                                item['api_category'] = category
                            all_results.extend(items)
                        break
                        
                except Exception as e:
                    if attempt == max_retries:
                        continue
                    continue
        
        return all_results[:30]

# ê³ ê¸‰ LangGraph ì›Œí¬í”Œë¡œìš° ë…¸ë“œë“¤
def advanced_keyword_search_node(state: BidSearchState) -> BidSearchState:
    """ê³ ê¸‰ í‚¤ì›Œë“œ ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        bid_manager = AdvancedBidManager()
        results = bid_manager.search_bids(state["query"])
        
        state["keyword_results"] = results
        state["messages"].append(f"ğŸ” ê³ ê¸‰ í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´ (ì „ë¬¸ê²€ìƒ‰ í™œìš©)")
        
        if not results:
            state["messages"].append("âš ï¸ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ë‹¤ë¥¸ ê²€ìƒ‰ ë°©ë²• í™œìš© í•„ìš”")
        
    except Exception as e:
        state["error"] = f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["keyword_results"] = []
        state["messages"].append(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    
    return state

def advanced_semantic_search_node(state: BidSearchState) -> BidSearchState:
    """ê³ ê¸‰ ì‹œë§¨í‹± ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        vector_engine = AdvancedVectorEngine()
        
        if vector_engine.is_loaded and state["keyword_results"]:
            results = vector_engine.semantic_search_with_explanation(
                state["query"], 
                state["keyword_results"], 
                top_k=15,
                explain=True
            )
            state["semantic_results"] = results
            state["messages"].append(f"ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´ (ì„¤ëª… ê°€ëŠ¥í•œ AI)")
            
            if results:
                avg_similarity = np.mean([r['similarity'] for r in results])
                state["messages"].append(f"ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.1%}")
        else:
            state["semantic_results"] = []
            if not vector_engine.is_loaded:
                state["messages"].append("âš ï¸ ë²¡í„° ëª¨ë¸ ë¯¸ë¡œë“œ - ì‹œë§¨í‹± ê²€ìƒ‰ ë¶ˆê°€")
            else:
                state["messages"].append("âš ï¸ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ì–´ ì‹œë§¨í‹± ê²€ìƒ‰ ìƒëµ")
        
    except Exception as e:
        state["error"] = f"ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["semantic_results"] = []
        state["messages"].append(f"âŒ ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    
    return state

def advanced_api_search_node(state: BidSearchState) -> BidSearchState:
    """ê³ ê¸‰ API ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        api_engine = AdvancedAPIEngine()
        
        # ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€
        total_existing = len(state["keyword_results"]) + len(state["semantic_results"])
        
        if total_existing < 8:
            results = api_engine.search_with_retry(state["query"])
            state["api_results"] = results
            state["messages"].append(f"ğŸŒ ì‹¤ì‹œê°„ API ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´ (ì¬ì‹œë„ ë¡œì§ ì ìš©)")
            
            if results:
                categories = list(set([r.get('api_category', 'Unknown') for r in results]))
                state["messages"].append(f"ğŸ“‚ ê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬: {', '.join(categories)}")
        else:
            state["api_results"] = []
            state["messages"].append(f"âœ… ì¶©ë¶„í•œ ê²€ìƒ‰ ê²°ê³¼({total_existing}ê±´)ë¡œ API ê²€ìƒ‰ ìƒëµ (íš¨ìœ¨ì„± ìµœì í™”)")
        
    except Exception as e:
        state["error"] = f"API ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["api_results"] = []
        state["messages"].append(f"âŒ API ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    
    return state

def advanced_combine_results_node(state: BidSearchState) -> BidSearchState:
    """ê³ ê¸‰ ê²°ê³¼ í†µí•© ë…¸ë“œ"""
    try:
        combined = {}
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ (ê¸°ë³¸ ì ìˆ˜ + ë­í‚¹ ë³´ë„ˆìŠ¤)
        for i, item in enumerate(state["keyword_results"]):
            bid_no = item.get("bidNtceNo") or item.get("bidntceno")
            if bid_no:
                ranking_bonus = max(0, 10 - i)  # ìƒìœ„ ê²°ê³¼ì— ë³´ë„ˆìŠ¤
                base_score = item.get('rank', 3) + ranking_bonus
                
                combined[bid_no] = {
                    **item,
                    "sources": ["í‚¤ì›Œë“œê²€ìƒ‰"],
                    "relevance_score": base_score,
                    "details": {
                        "keyword_rank": i + 1,
                        "text_rank": item.get('rank', 0)
                    }
                }
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ (AI ì ìˆ˜)
        for result in state["semantic_results"]:
            item = result["document"]
            bid_no = item.get("bidNtceNo") or item.get("bidntceno")
            if bid_no:
                ai_score = result["final_score"] * 15
                
                if bid_no in combined:
                    combined[bid_no]["sources"].append("AIì‹œë§¨í‹±")
                    combined[bid_no]["relevance_score"] += ai_score
                    combined[bid_no]["similarity"] = result["similarity"]
                    combined[bid_no]["explanation"] = result["explanation"]
                else:
                    combined[bid_no] = {
                        **item,
                        "sources": ["AIì‹œë§¨í‹±"],
                        "relevance_score": ai_score,
                        "similarity": result["similarity"],
                        "explanation": result["explanation"]
                    }
        
        # API ê²€ìƒ‰ ê²°ê³¼ (ì‹¤ì‹œê°„ ë³´ë„ˆìŠ¤)
        for item in state["api_results"]:
            bid_no = item.get("bidNtceNo")
            if bid_no:
                api_bonus = 5  # ì‹¤ì‹œê°„ ë°ì´í„° ë³´ë„ˆìŠ¤
                
                if bid_no in combined:
                    combined[bid_no]["sources"].append("ì‹¤ì‹œê°„API")
                    combined[bid_no]["relevance_score"] += api_bonus
                else:
                    combined[bid_no] = {
                        **item,
                        "sources": ["ì‹¤ì‹œê°„API"],
                        "relevance_score": api_bonus
                    }
        
        # ìµœì¢… ì •ë ¬ ë° í†µê³„
        combined_list = list(combined.values())
        combined_list.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
        
        state["combined_results"] = combined_list[:20]
        
        # í†µê³„ ì •ë³´
        stats = {
            "total_unique": len(combined_list),
            "keyword_only": len([r for r in combined_list if r["sources"] == ["í‚¤ì›Œë“œê²€ìƒ‰"]]),
            "ai_enhanced": len([r for r in combined_list if "AIì‹œë§¨í‹±" in r["sources"]]),
            "api_included": len([r for r in combined_list if "ì‹¤ì‹œê°„API" in r["sources"]]),
            "multi_source": len([r for r in combined_list if len(r["sources"]) > 1])
        }
        
        state["statistics"] = stats
        state["messages"].append(f"ğŸ”„ ê³ ê¸‰ ê²°ê³¼ í†µí•© ì™„ë£Œ: {len(state['combined_results'])}ê±´")
        state["messages"].append(f"ğŸ“ˆ ë‹¤ì¤‘ì†ŒìŠ¤ ë§¤ì¹­: {stats['multi_source']}ê±´, AI ê°•í™”: {stats['ai_enhanced']}ê±´")
        
    except Exception as e:
        state["error"] = f"ê²°ê³¼ í†µí•© ì˜¤ë¥˜: {str(e)}"
        state["combined_results"] = []
        state["statistics"] = {}
        state["messages"].append(f"âŒ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {str(e)}")
    
    return state

def advanced_generate_answer_node(state: BidSearchState) -> BidSearchState:
    """ê³ ê¸‰ AI ë‹µë³€ ìƒì„± ë…¸ë“œ"""
    try:
        from langchain_openai import ChatOpenAI
        config = get_app_config()
        
        llm = ChatOpenAI(
            api_key=config.openai.api_key,
            model=config.openai.model,
            temperature=0.5,  # ë” ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
            max_tokens=800
        )
        
        if not state["combined_results"]:
            state["final_answer"] = f"'{state['query']}'ì— ëŒ€í•œ ì…ì°° ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ë„“í˜€ë³´ì„¸ìš”."
            return state
        
        # ê³ ê¸‰ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "## ğŸ” ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n\n"
        
        # í†µê³„ ì •ë³´
        stats = state.get("statistics", {})
        if stats:
            context += f"**ê²€ìƒ‰ í†µê³„**: ì´ {stats.get('total_unique', 0)}ê°œ ê³ ìœ  ê³µê³  ë°œê²¬\n"
            context += f"- ë‹¤ì¤‘ì†ŒìŠ¤ ë§¤ì¹­: {stats.get('multi_source', 0)}ê±´\n"
            context += f"- AI ì‹œë§¨í‹± ê°•í™”: {stats.get('ai_enhanced', 0)}ê±´\n"
            context += f"- ì‹¤ì‹œê°„ API í¬í•¨: {stats.get('api_included', 0)}ê±´\n\n"
        
        context += "## ğŸ“‹ ìƒìœ„ ê²€ìƒ‰ ê²°ê³¼:\n\n"
        
        for i, result in enumerate(state["combined_results"][:5]):
            sources = ", ".join(result.get("sources", []))
            score = result.get("relevance_score", 0)
            
            context += f"**{i+1}. {result.get('bidNtceNm') or result.get('bidntcenm', 'ì œëª©ì—†ìŒ')}**\n"
            context += f"- ë°œì£¼ê¸°ê´€: {result.get('ntceInsttNm') or result.get('ntceinsttm', 'ê¸°ê´€ì—†ìŒ')}\n"
            context += f"- ì‚¬ì—…ë¶„ë¥˜: {result.get('bsnsDivNm') or result.get('bsnsdivnm', 'ë¶„ë¥˜ì—†ìŒ')}\n"
            context += f"- ê²€ìƒ‰ë°©ë²•: {sources}\n"
            context += f"- ê´€ë ¨ë„ì ìˆ˜: {score:.1f}ì \n"
            
            # AI ì„¤ëª… ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if 'explanation' in result:
                exp = result['explanation']
                if exp.get('matched_terms'):
                    context += f"- ë§¤ì¹­í‚¤ì›Œë“œ: {', '.join(exp['matched_terms'])}\n"
                context += f"- AIìœ ì‚¬ë„: {exp.get('semantic_similarity', 0):.1%}\n"
            
            # ì˜ˆì‚° ì •ë³´
            amount = result.get('asignBdgtAmt') or result.get('asignbdgtamt', 0)
            if amount:
                context += f"- ì‚¬ì—…ì˜ˆì‚°: {convert_to_won_format(amount)}\n"
            
            context += "\n"
        
        # ê³ ê¸‰ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³µê³µì…ì°° ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: "{state['query']}"

{context}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ êµ¬ì„±:
1. **í•µì‹¬ ìš”ì•½**: ê²€ìƒ‰ ê²°ê³¼ì˜ ì£¼ìš” íŠ¹ì§• (2-3ë¬¸ì¥)
2. **ì¶”ì²œ ê³µê³ **: ê°€ì¥ ì í•©í•œ 1-2ê°œ ê³µê³ ì™€ ê·¸ ì´ìœ 
3. **ì…ì°° ì „ëµ**: í•´ë‹¹ ë¶„ì•¼ ì…ì°° ì°¸ì—¬ì‹œ ê³ ë ¤ì‚¬í•­
4. **ì¶”ê°€ ì¡°ì¹˜**: ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì œì•ˆ

ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ, ì‹¤ë¬´ì— ë„ì›€ì´ ë˜ë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ 6-8ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = llm.invoke(prompt)
        state["final_answer"] = response.content
        state["messages"].append("ğŸ¤– ì „ë¬¸ AI ë¶„ì„ ì™„ë£Œ (ê³ ê¸‰ í”„ë¡¬í”„íŒ… ì ìš©)")
        
    except Exception as e:
        state["error"] = f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}"
        state["final_answer"] = "ì „ë¬¸ ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”."
        state["messages"].append(f"âŒ AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    return state

# ê³ ê¸‰ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
@st.cache_resource
def create_advanced_workflow():
    """ê³ ê¸‰ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    try:
        from langgraph.graph import StateGraph, END
        
        workflow = StateGraph(BidSearchState)
        
        # ê³ ê¸‰ ë…¸ë“œë“¤ ì¶”ê°€
        workflow.add_node("advanced_keyword", advanced_keyword_search_node)
        workflow.add_node("advanced_semantic", advanced_semantic_search_node)
        workflow.add_node("advanced_api", advanced_api_search_node)
        workflow.add_node("advanced_combine", advanced_combine_results_node)
        workflow.add_node("advanced_answer", advanced_generate_answer_node)
        
        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("advanced_keyword")
        workflow.add_edge("advanced_keyword", "advanced_semantic")
        workflow.add_edge("advanced_semantic", "advanced_api")
        workflow.add_edge("advanced_api", "advanced_combine")
        workflow.add_edge("advanced_combine", "advanced_answer")
        workflow.add_edge("advanced_answer", END)
        
        return workflow.compile()
    except Exception as e:
        st.error(f"ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# AI ì±—ë´‡ í´ë˜ìŠ¤ (ìµœì¢… ë²„ì „)
class UltimateAIChatbot:
    def __init__(self):
        try:
            from langchain_openai import ChatOpenAI
            config = get_app_config()
            self.llm = ChatOpenAI(
                api_key=config.openai.api_key,
                model=config.openai.model,
                temperature=0.7
            )
        except Exception as e:
            st.error(f"Ultimate AI ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None

    def get_ultimate_response(self, question: str, search_results: list, semantic_results: list = None, context_history: list = None) -> str:
        """ê¶ê·¹ì˜ AI ì‘ë‹µ ìƒì„±"""
        if not self.llm:
            return "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ê³ ê¸‰ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "## ğŸ¯ ì…ì°° ê³µê³  ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n\n"
            
            # ì´ì „ ëŒ€í™” ê³ ë ¤
            if context_history:
                context += "### ğŸ“œ ì´ì „ ëŒ€í™” ë§¥ë½:\n"
                for msg in context_history[-3:]:  # ìµœê·¼ 3ê°œë§Œ
                    if msg['role'] == 'user':
                        context += f"- ì‚¬ìš©ì: {msg['content']}\n"
                context += "\n"
            
            # í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼
            if search_results:
                context += "### ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼:\n"
                for i, bid in enumerate(search_results[:3]):
                    context += f"{i+1}. **{bid.get('bidNtceNm', 'ì œëª©ì—†ìŒ')}**\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceInsttNm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë¶„ë¥˜: {bid.get('bsnsDivNm', 'ë¶„ë¥˜ì—†ìŒ')}\n"
                    context += f"   - ì˜ˆì‚°: {convert_to_won_format(bid.get('asignBdgtAmt', 0))}\n\n"
            
            # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼
            if semantic_results:
                context += "### ğŸ¯ AI ì‹œë§¨í‹± ë¶„ì„ ê²°ê³¼:\n"
                for i, result in enumerate(semantic_results[:3]):
                    bid = result['document']
                    similarity = result['similarity']
                    explanation = result.get('explanation', {})
                    
                    context += f"{i+1}. **{bid.get('bidNtceNm', 'ì œëª©ì—†ìŒ')}** (AI ìœ ì‚¬ë„: {similarity:.1%})\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceInsttNm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(explanation.get('matched_terms', []))}\n"
                    context += f"   - ì˜ˆì‚°: {convert_to_won_format(bid.get('asignBdgtAmt', 0))}\n\n"
            
            # ê³ ê¸‰ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê³µê³µì…ì°° ì „ë¬¸ AI ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤.

í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸: "{question}"

{context}

ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì „ë¬¸ì ì´ê³  ê°œì¸í™”ëœ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:

ğŸ¯ **ë‹µë³€ ì›ì¹™**:
1. **ë§ì¶¤í˜• ë¶„ì„**: ì‚¬ìš©ì ì§ˆë¬¸ì˜ ìˆ¨ì€ ì˜ë„ íŒŒì•…
2. **ì‹¤ë¬´ ì¤‘ì‹¬**: ì‹¤ì œ ì…ì°° ì°¸ì—¬ì— ë„ì›€ë˜ëŠ” êµ¬ì²´ì  ì¡°ì–¸
3. **ìœ„í—˜ ê´€ë¦¬**: ì£¼ì˜ì‚¬í•­ê³¼ í•¨ì • ìš”ì†Œ ì‚¬ì „ ì•ˆë‚´
4. **ê¸°íšŒ ë°œêµ´**: ë†“ì¹  ìˆ˜ ìˆëŠ” ì¶”ê°€ ê¸°íšŒ ì œì‹œ
5. **ë‹¨ê³„ë³„ ê°€ì´ë“œ**: ë‹¤ìŒì— ì·¨í•´ì•¼ í•  êµ¬ì²´ì  í–‰ë™ ì œì•ˆ

ë‹µë³€ êµ¬ì„±:
- **í•µì‹¬ ì¸ì‚¬ì´íŠ¸** (2ë¬¸ì¥)
- **ì¶”ì²œ ì „ëµ** (2-3ë¬¸ì¥) 
- **ì£¼ì˜ì‚¬í•­** (1-2ë¬¸ì¥)
- **Next Step** (1ë¬¸ì¥)

ì „ë¬¸ê°€ì  í†µì°°ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ 7-8ë¬¸ì¥ì˜ ë°€ë„ ë†’ì€ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            return f"Ultimate AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def convert_to_won_format(amount):
    """ê¸ˆì•¡ì„ ì› ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
    try:
        if not amount:
            return "ê³µê³  ì°¸ì¡°"
        
        if isinstance(amount, str):
            amount = amount.replace(",", "")
        
        amount = float(amount)
        if amount >= 100000000:
            return f"{amount/100000000:.1f}ì–µì›"
        elif amount >= 10000:
            return f"{amount/10000:.1f}ë§Œì›"
        else:
            return f"{int(amount):,}ì›"
    except:
        return "ê³µê³  ì°¸ì¡°"

def format_similarity_advanced(similarity):
    """ê³ ê¸‰ ìœ ì‚¬ë„ í¬ë§·íŒ…"""
    if similarity >= 0.8:
        return f'<span class="similarity-high">ğŸ”¥ {similarity:.1%}</span>'
    elif similarity >= 0.6:
        return f'<span class="similarity-high">âœ¨ {similarity:.1%}</span>'
    elif similarity >= 0.4:
        return f'<span class="similarity-medium">ğŸ’¡ {similarity:.1%}</span>'
    else:
        return f'<span class="similarity-low">ğŸ“ {similarity:.1%}</span>'

def create_statistics_dashboard(stats):
    """í†µê³„ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    if not stats:
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats.get('total_bids', 0):,}</div>
            <div class="stats-label">ì „ì²´ ê³µê³ </div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats.get('active_bids', 0):,}</div>
            <div class="stats-label">ì§„í–‰ ì¤‘</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats.get('unique_orgs', 0):,}</div>
            <div class="stats-label">ë°œì£¼ê¸°ê´€</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        avg_amount = stats.get('avg_amount', 0)
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{convert_to_won_format(avg_amount)}</div>
            <div class="stats-label">í‰ê·  ì˜ˆì‚°</div>
        </div>
        """, unsafe_allow_html=True)

# ë§¤ë‹ˆì € ì´ˆê¸°í™”
@st.cache_resource
def init_ultimate_managers():
    check_secrets()
    bid_manager = AdvancedBidManager()
    vector_engine = AdvancedVectorEngine()
    chatbot = UltimateAIChatbot()
    workflow = create_advanced_workflow()
    return bid_manager, vector_engine, chatbot, workflow

# ìµœì¢… ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬
def process_ultimate_question(question: str, chatbot: UltimateAIChatbot, bid_manager: AdvancedBidManager, vector_engine: AdvancedVectorEngine):
    """Ultimate ì§ˆë¬¸ ì²˜ë¦¬"""
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.chat_messages.append({"role": "user", "content": question})
    
    # ì‘ë‹µ ìƒì„±
    with st.spinner("ğŸ§  Ultimate AIê°€ ë‹¤ì°¨ì› ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_results = bid_manager.search_bids(question)
        
        # ì‹œë§¨í‹± ê²€ìƒ‰
        semantic_results = []
        if vector_engine.is_loaded and keyword_results:
            semantic_results = vector_engine.semantic_search_with_explanation(
                question, keyword_results, top_k=5, explain=True
            )
        
        # Ultimate AI ì‘ë‹µ ìƒì„±
        response = chatbot.get_ultimate_response(
            question, 
            keyword_results, 
            semantic_results,
            st.session_state.chat_messages
        )
    
    # ì‘ë‹µ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response)
        
        # ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if semantic_results:
            with st.expander("ğŸ”¬ AI ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                for i, result in enumerate(semantic_results):
                    bid = result['document']
                    similarity = result['similarity']
                    explanation = result.get('explanation', {})
                    
                    st.markdown(f"**{i+1}. {bid.get('bidNtceNm', 'ì œëª©ì—†ìŒ')}**")
                    
                    col1, col2 = st.columns([1, 2])
                    with col1:
                        st.markdown(f"AI ìœ ì‚¬ë„: {format_similarity_advanced(similarity)}", unsafe_allow_html=True)
                        st.caption(f"ìµœì¢…ì ìˆ˜: {result.get('final_score', 0):.2f}")
                    
                    with col2:
                        st.caption(f"ê¸°ê´€: {bid.get('ntceInsttNm', 'N/A')}")
                        if explanation.get('matched_terms'):
                            st.caption(f"ğŸ”‘ ë§¤ì¹­: {', '.join(explanation['matched_terms'])}")
                    
                    st.divider()
    
    st.session_state.chat_messages.append({"role": "assistant", "content": response})

# ê³ ê¸‰ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
def run_ultimate_workflow(query: str, workflow):
    """Ultimate LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    if not workflow:
        return None, ["âŒ Ultimate ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    try:
        initial_state = {
            "query": query,
            "keyword_results": [],
            "semantic_results": [],
            "api_results": [],
            "combined_results": [],
            "final_answer": "",
            "messages": [],
            "error": None,
            "statistics": {}
        }
        
        final_state = workflow.invoke(initial_state)
        return final_state, final_state.get("messages", [])
        
    except Exception as e:
        return None, [f"âŒ Ultimate ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"]

# ë©”ì¸ í•¨ìˆ˜
def main():
    # Ultimate í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš€ AI ì…ì°° ê³µê³  í†µí•© í”Œë«í¼</h1>
        <p>
            ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰ Ã— ğŸ”„ LangGraph ì›Œí¬í”Œë¡œìš° Ã— ğŸŒ ì‹¤ì‹œê°„ API<br>
            ğŸ’¡ Ultimate Intelligence for Smart Bidding
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ultimate ë§¤ë‹ˆì € ì´ˆê¸°í™”
    bid_manager, vector_engine, chatbot, workflow = init_ultimate_managers()
    
    # ì‚¬ì´ë“œë°”ì— í†µê³„ ëŒ€ì‹œë³´ë“œ
    with st.sidebar:
        st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ í†µê³„")
        try:
            stats = bid_manager.get_statistics()
            create_statistics_dashboard(stats)
            
            if stats.get('categories'):
                st.markdown("### ğŸ“‚ ë¶„ì•¼ë³„ ë¶„í¬")
                categories_df = pd.DataFrame(stats['categories'][:5])
                if not categories_df.empty:
                    st.bar_chart(categories_df.set_index('category')['count'])
        except:
            st.info("í†µê³„ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    
    # Ultimate íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“¢ ìŠ¤ë§ˆíŠ¸ ëŒ€ì‹œë³´ë“œ", 
        "ğŸ” ê³ ê¸‰ í‚¤ì›Œë“œ ê²€ìƒ‰", 
        "ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰", 
        "âš¡ Ultimate LangGraph",
        "ğŸ§  Ultimate AI ìƒë‹´",
        "ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸"
    ])
    
    with tab1:
        st.subheader("ğŸ“¢ ìŠ¤ë§ˆíŠ¸ ì…ì°° ëŒ€ì‹œë³´ë“œ")
        
        # ê³ ê¸‰ í•„í„°
        with st.expander("ğŸ›ï¸ ê³ ê¸‰ í•„í„° ì„¤ì •"):
            col1, col2, col3 = st.columns(3)
            with col1:
                categories = st.multiselect("ë¶„ì•¼ ì„ íƒ", ["ê³µì‚¬", "ìš©ì—­", "ë¬¼í’ˆ", "ì™¸ì"])
            with col2:
                min_amount = st.number_input("ìµœì†Œ ì˜ˆì‚° (ë§Œì›)", min_value=0, value=0, step=1000)
                max_amount = st.number_input("ìµœëŒ€ ì˜ˆì‚° (ë§Œì›)", min_value=0, value=0, step=1000)
            with col3:
                date_range = st.date_input("ê³µê³ ì¼ ë²”ìœ„", value=[datetime.now().date() - timedelta(days=30), datetime.now().date()])
        
        # í•„í„° ì ìš©
        filters = {}
        if categories:
            filters['categories'] = categories
        if min_amount > 0:
            filters['min_amount'] = min_amount * 10000
        if max_amount > 0:
            filters['max_amount'] = max_amount * 10000
        if len(date_range) == 2:
            filters['date_from'] = date_range[0].strftime('%Y%m%d')
            filters['date_to'] = date_range[1].strftime('%Y%m%d')
        
        # ë°ì´í„° ë¡œë“œ
        bids = bid_manager.get_live_bids(limit=50, filters=filters if any(filters.values()) else None)
        
        if bids:
            st.success(f"ğŸ¯ {len(bids)}ê±´ì˜ ë§ì¶¤ ê³µê³ ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
            
            # ê³ ê¸‰ ê²°ê³¼ í‘œì‹œ
            for i, bid in enumerate(bids):
                with st.container():
                    st.markdown(f"""
                    <div class="result-card">
                        <h4 style="margin-bottom: 0.5rem; color: #007bff;">
                            {bid.get('bidNtceNm', 'ì œëª© ì—†ìŒ')}
                        </h4>
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                            <div>
                                <span style="color: #6c757d;">ğŸ¢ {bid.get('ntceInsttNm', 'ê¸°ê´€ëª… ì—†ìŒ')}</span>
                                <span style="margin-left: 1rem; color: #6c757d;">ğŸ“ {bid.get('bsnsDivNm', 'ë¶„ë¥˜ ì—†ìŒ')}</span>
                            </div>
                            <div style="font-weight: bold; color: #28a745;">
                                ğŸ’° {convert_to_won_format(bid.get('asignBdgtAmt', 0))}
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    col1, col2 = st.columns([4, 1])
                    with col2:
                        if st.button("ìƒì„¸ë¶„ì„", key=f"tab1_detail_{i}"):
                            st.session_state.selected_bid = bid
                            st.session_state.show_detail = True
                            st.rerun()
        else:
            st.warning("ì¡°ê±´ì— ë§ëŠ” ì…ì°° ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    
    with tab2:
        st.subheader("ğŸ” ê³ ê¸‰ í‚¤ì›Œë“œ ê²€ìƒ‰")
        st.info("ğŸ’¡ ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„ê³¼ ë­í‚¹ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ì •ë°€ ê²€ìƒ‰")
        
        # ê³ ê¸‰ ê²€ìƒ‰ UI
        col1, col2 = st.columns([3, 1])
        with col1:
            keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
                                   placeholder="ì˜ˆ: AI ê°œë°œ, ë¹…ë°ì´í„° ë¶„ì„, í´ë¼ìš°ë“œ êµ¬ì¶•")
        with col2:
            search_mode = st.selectbox("ê²€ìƒ‰ ëª¨ë“œ", ["ì •í™•ë„ ìš°ì„ ", "ìµœì‹ ìˆœ ìš°ì„ "])
        
        if st.button("ğŸ” ê³ ê¸‰ ê²€ìƒ‰", type="primary", key="tab2_advanced_search"):
            if keyword:
                with st.spinner("ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    results = bid_manager.search_bids(keyword)
                    
                    if results:
                        st.success(f"ğŸ¯ '{keyword}'ì— ëŒ€í•œ ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´")
                        
                        # ê²€ìƒ‰ í’ˆì§ˆ í‘œì‹œ
                        if results[0].get('rank'):
                            avg_rank = np.mean([r.get('rank', 0) for r in results[:5]])
                            st.info(f"ğŸ“ˆ ê²€ìƒ‰ í’ˆì§ˆ ì ìˆ˜: {avg_rank:.2f}")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        for i, result in enumerate(results):
                            with st.container():
                                st.markdown(f"""
                                <div class="result-card">
                                    <div style="display: flex; justify-content: space-between; align-items: start;">
                                        <div style="flex: 1;">
                                            <h4 style="color: #007bff; margin-bottom: 0.5rem;">
                                                {result.get('bidNtceNm', 'ì œëª© ì—†ìŒ')}
                                            </h4>
                                            <p style="color: #6c757d; margin-bottom: 0.5rem;">
                                                ğŸ¢ {result.get('ntceInsttNm', 'ê¸°ê´€ëª… ì—†ìŒ')} | 
                                                ğŸ“ {result.get('bsnsDivNm', 'ë¶„ë¥˜ ì—†ìŒ')}
                                            </p>
                                        </div>
                                        <div style="text-align: right;">
                                            <div style="font-weight: bold; color: #28a745;">
                                                {convert_to_won_format(result.get('asignBdgtAmt', 0))}
                                            </div>
                                            {"<div style='font-size: 0.8rem; color: #ffc107;'>ğŸ† ë­í‚¹: " + str(result.get('rank', 0)) + "</div>" if result.get('rank') else ""}
                                        </div>
                                    </div>
                                </div>
                                """, unsafe_allow_html=True)
                                st.divider()
                    else:
                        st.warning(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.subheader("ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰")
        st.info("ğŸ§  ì„¤ëª… ê°€ëŠ¥í•œ AIê°€ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ìµœì ì˜ ê³µê³ ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!")
        
        if not vector_engine.is_loaded:
            st.error("âš ï¸ AI ë²¡í„° ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            # AI ê²€ìƒ‰ UI
            col1, col2 = st.columns([3, 1])
            with col1:
                semantic_query = st.text_input("ìì—°ì–´ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”", 
                                             placeholder="ì˜ˆ: ìŠ¤ë§ˆíŠ¸ì‹œí‹° IoT í”Œë«í¼ êµ¬ì¶•, ì˜¨ë¼ì¸ êµìœ¡ ì‹œìŠ¤í…œ ê°œë°œ")
            with col2:
                ai_sensitivity = st.selectbox("AI ë¯¼ê°ë„", ["ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ"])
            
            # ë¯¼ê°ë„ì— ë”°ë¥¸ ì„ê³„ê°’ ì„¤ì •
            threshold_map = {"ë†’ìŒ": 0.2, "ë³´í†µ": 0.3, "ë‚®ìŒ": 0.4}
            threshold = threshold_map[ai_sensitivity]
            
            if st.button("ğŸ¯ AI ê²€ìƒ‰", type="primary", key="tab3_ai_search"):
                if semantic_query:
                    with st.spinner("ğŸ§  AIê°€ ì˜ë¯¸ë¡ ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # í›„ë³´ ê²€ìƒ‰
                        candidates = bid_manager.search_bids(semantic_query)
                        
                        if candidates:
                            # AI ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰
                            semantic_results = vector_engine.semantic_search_with_explanation(
                                semantic_query, candidates, top_k=15, explain=True
                            )
                            
                            if semantic_results:
                                st.success(f"ğŸ¯ AIê°€ ë°œê²¬í•œ ê´€ë ¨ ê³µê³ : {len(semantic_results)}ê±´")
                                
                                # AI ë¶„ì„ í†µê³„
                                avg_similarity = np.mean([r['similarity'] for r in semantic_results])
                                max_similarity = max([r['similarity'] for r in semantic_results])
                                st.info(f"ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.1%} | ìµœê³  ìœ ì‚¬ë„: {max_similarity:.1%}")
                                
                                # ê²°ê³¼ í‘œì‹œ
                                for i, result in enumerate(semantic_results):
                                    bid = result['document']
                                    explanation = result.get('explanation', {})
                                    
                                    with st.container():
                                        col1, col2, col3 = st.columns([0.5, 2.5, 1])
                                        
                                        # AI ì ìˆ˜ í‘œì‹œ
                                        with col1:
                                            st.markdown(format_similarity_advanced(result['similarity']), 
                                                      unsafe_allow_html=True)
                                            st.caption(f"ì¢…í•©: {result.get('final_score', 0):.2f}")
                                        
                                        # ê³µê³  ì •ë³´
                                        with col2:
                                            st.markdown(f"**{bid.get('bidNtceNm', 'ì œëª© ì—†ìŒ')}**")
                                            st.caption(f"ğŸ¢ {bid.get('ntceInsttNm', 'ê¸°ê´€ëª… ì—†ìŒ')} | ğŸ“ {bid.get('bsnsDivNm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                                            
                                            # AI ì„¤ëª…
                                            if explanation.get('matched_terms'):
                                                st.caption(f"ğŸ”‘ AI ë§¤ì¹­: {', '.join(explanation['matched_terms'])}")
                                        
                                        # ì˜ˆì‚°
                                        with col3:
                                            st.write(convert_to_won_format(bid.get('asignBdgtAmt', 0)))
                                        
                                        st.divider()
                            else:
                                st.warning("AIê°€ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab4:
        st.subheader("âš¡ Ultimate LangGraph ì›Œí¬í”Œë¡œìš°")
        st.info("ğŸ”¥ ìµœì²¨ë‹¨ AI ì›Œí¬í”Œë¡œìš°ê°€ ë‹¤ì°¨ì› ê²€ìƒ‰ê³¼ ë¶„ì„ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤!")
        
        # Ultimate ê²€ìƒ‰ UI
        col1, col2 = st.columns([3, 1])
        with col1:
            ultimate_query = st.text_input("Ultimate ê²€ìƒ‰ ì§ˆì˜", 
                                         placeholder="ì˜ˆ: ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼ ê°œë°œ í”„ë¡œì íŠ¸, íƒ„ì†Œì¤‘ë¦½ ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ êµ¬ì¶•")
        with col2:
            analysis_depth = st.selectbox("ë¶„ì„ ê¹Šì´", ["Standard", "Deep", "Ultimate"])
        
        col1, col2 = st.columns([1, 1])
        with col1:
            show_workflow = st.checkbox("ì›Œí¬í”Œë¡œìš° ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ", value=True)
        with col2:
            enable_api = st.checkbox("ì‹¤ì‹œê°„ API ê²€ìƒ‰ í¬í•¨", value=True)
        
        if st.button("âš¡ Ultimate ê²€ìƒ‰ ì‹¤í–‰", type="primary", key="tab4_ultimate_search"):
            if ultimate_query:
                with st.spinner("ğŸš€ Ultimate AI ì›Œí¬í”Œë¡œìš°ê°€ ë‹¤ì°¨ì› ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
                    final_state, messages = run_ultimate_workflow(ultimate_query, workflow)
                    
                    if final_state:
                        # ì›Œí¬í”Œë¡œìš° ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ
                        if show_workflow and messages:
                            st.markdown("### ğŸ”„ Ultimate ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê³¼ì •")
                            
                            progress_bar = st.progress(0)
                            status_placeholder = st.empty()
                            
                            for i, msg in enumerate(messages):
                                progress = (i + 1) / len(messages)
                                progress_bar.progress(progress)
                                status_placeholder.text(f"ì§„í–‰ ì¤‘: {msg}")
                                
                                if "âœ…" in msg or "ğŸ”" in msg or "ğŸ¯" in msg or "ğŸŒ" in msg:
                                    st.markdown(f'<div class="workflow-step workflow-success">{msg}</div>', 
                                              unsafe_allow_html=True)
                                elif "âš ï¸" in msg or "â„¹ï¸" in msg:
                                    st.markdown(f'<div class="workflow-step workflow-warning">{msg}</div>', 
                                              unsafe_allow_html=True)
                                elif "âŒ" in msg:
                                    st.markdown(f'<div class="workflow-step workflow-error">{msg}</div>', 
                                              unsafe_allow_html=True)
                                else:
                                    st.markdown(f'<div class="workflow-step">{msg}</div>', 
                                              unsafe_allow_html=True)
                            
                            progress_bar.progress(1.0)
                            status_placeholder.success("ğŸ‰ Ultimate ë¶„ì„ ì™„ë£Œ!")
                        
                        st.markdown("---")
                        
                        # Ultimate AI ë¶„ì„ ê²°ê³¼
                        if final_state.get("final_answer"):
                            st.markdown("### ğŸ§  Ultimate AI ì „ë¬¸ ë¶„ì„")
                            st.success(final_state["final_answer"])
                        
                        # í†µê³„ ëŒ€ì‹œë³´ë“œ
                        if final_state.get("statistics"):
                            st.markdown("### ğŸ“Š ê²€ìƒ‰ ì„±ê³¼ ë¶„ì„")
                            stats = final_state["statistics"]
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì´ ë°œê²¬", f"{stats.get('total_unique', 0)}ê±´")
                            with col2:
                                st.metric("AI ê°•í™”", f"{stats.get('ai_enhanced', 0)}ê±´")
                            with col3:
                                st.metric("ë‹¤ì¤‘ì†ŒìŠ¤", f"{stats.get('multi_source', 0)}ê±´")
                            with col4:
                                st.metric("API í¬í•¨", f"{stats.get('api_included', 0)}ê±´")
                        
                        # Ultimate ê²€ìƒ‰ ê²°ê³¼
                        if final_state.get("combined_results"):
                            st.markdown(f"### ğŸ† Ultimate ê²€ìƒ‰ ê²°ê³¼ ({len(final_state['combined_results'])}ê±´)")
                            
                            for i, result in enumerate(final_state["combined_results"][:12]):
                                with st.container():
                                    st.markdown(f"""
                                    <div class="advanced-card">
                                        <div style="display: flex; justify-content: space-between; align-items: start;">
                                            <div style="flex: 1;">
                                                <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                                                    <span style="background: linear-gradient(45deg, #007bff, #0056b3); color: white; 
                                                                 padding: 4px 8px; border-radius: 12px; font-size: 0.8rem; font-weight: bold;">
                                                        #{i+1}
                                                    </span>
                                                    <span style="margin-left: 0.5rem; font-weight: 600; color: #495057;">
                                                        ê´€ë ¨ë„: {result.get('relevance_score', 0):.1f}ì 
                                                    </span>
                                                </div>
                                                <h4 style="color: #007bff; margin-bottom: 0.5rem;">
                                                    {result.get('bidNtceNm') or result.get('bidntcenm', 'ì œëª© ì—†ìŒ')}
                                                </h4>
                                                <p style="color: #6c757d; margin-bottom: 0.8rem;">
                                                    ğŸ¢ {result.get('ntceInsttNm') or result.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')}
                                                </p>
                                                <div style="display: flex; align-items: center; gap: 1rem;">
                                                    <span style="background: #e9ecef; padding: 2px 8px; border-radius: 12px; font-size: 0.8rem;">
                                                        ğŸ·ï¸ {', '.join(result.get('sources', []))}
                                                    </span>
                                                    {"<span style='color: #28a745; font-weight: bold;'>ğŸ¯ " + format_similarity_advanced(result.get('similarity', 0)).replace('<span class="similarity-high">', '').replace('<span class="similarity-medium">', '').replace('<span class="similarity-low">', '').replace('</span>', '') + "</span>" if 'similarity' in result else ""}
                                                </div>
                                            </div>
                                            <div style="text-align: right; margin-left: 1rem;">
                                                <div style="font-weight: bold; color: #28a745; font-size: 1.1rem;">
                                                    {convert_to_won_format(result.get('asignBdgtAmt') or result.get('asignbdgtamt', 0))}
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    """, unsafe_allow_html=True)
                        else:
                            st.warning("Ultimate ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.error("Ultimate ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("Ultimate ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab5:
        st.subheader("ğŸ§  Ultimate AI ìƒë‹´")
        st.info("ğŸ’ ìµœê³  ìˆ˜ì¤€ì˜ AIê°€ ë‹¹ì‹ ì˜ ì…ì°° ì „ëµì„ ê°œì¸í™”ëœ ë§ì¶¤ ì¡°ì–¸ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤!")
        
        # Ultimate ì˜ˆì‹œ ì§ˆë¬¸
        st.markdown("**ğŸ¯ Ultimate ì§ˆë¬¸ ì˜ˆì‹œ:**")
        ultimate_questions = [
            "ğŸš€ ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼ ê°œë°œ í”„ë¡œì íŠ¸ ì¶”ì²œí•´ì£¼ì„¸ìš”",
            "ğŸŒ± íƒ„ì†Œì¤‘ë¦½ ê´€ë ¨ ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ ì…ì°° ì „ëµì€?",
            "ğŸ¥ ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ í”Œë«í¼ êµ¬ì¶• ê¸°íšŒ ë¶„ì„",
            "ğŸ“ ì—ë“€í…Œí¬ AI í•™ìŠµ ì‹œìŠ¤í…œ ê°œë°œ ë™í–¥"
        ]
        
        cols = st.columns(2)
        for idx, question in enumerate(ultimate_questions):
            if cols[idx % 2].button(question, key=f"tab5_ultimate_{idx}"):
                st.session_state.pending_question = question
                st.rerun()
        
        if st.button("ğŸ”„ Ultimate ëŒ€í™” ì´ˆê¸°í™”", key="tab5_ultimate_reset"):
            st.session_state.chat_messages = []
            st.rerun()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []
        
        # ì´ì „ ëŒ€í™” í‘œì‹œ (ê³ ê¸‰ ìŠ¤íƒ€ì¼)
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                if message["role"] == "assistant":
                    st.markdown(f"""
                    <div style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); 
                                padding: 1rem; border-radius: 10px; border-left: 4px solid #007bff;">
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(message["content"])
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
        if hasattr(st.session_state, 'pending_question'):
            question = st.session_state.pending_question
            del st.session_state.pending_question
            process_ultimate_question(question, chatbot, bid_manager, vector_engine)
            st.rerun()
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ğŸ§  Ultimate AIì—ê²Œ ì „ë¬¸ì ì¸ ì…ì°° ìƒë‹´ì„ ìš”ì²­í•˜ì„¸ìš”"):
            process_ultimate_question(prompt, chatbot, bid_manager, vector_engine)
    
    with tab6:
        st.subheader("ğŸ“Š ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        st.info("ğŸ“ˆ ì…ì°° ì‹œì¥ ë™í–¥ê³¼ ê°œì¸í™”ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤")
        
        try:
            # í†µê³„ ë°ì´í„° ë¡œë“œ
            stats = bid_manager.get_statistics()
            
            if stats:
                # ë©”ì¸ í†µê³„ ëŒ€ì‹œë³´ë“œ
                st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ì…ì°° ì‹œì¥ í˜„í™©")
                create_statistics_dashboard(stats)
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ì„
                if stats.get('categories'):
                    st.markdown("### ğŸ·ï¸ ë¶„ì•¼ë³„ ì…ì°° ë™í–¥")
                    
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        # ì°¨íŠ¸ ìƒì„±
                        try:
                            import plotly.express as px
                            import plotly.graph_objects as go
                            
                            categories_df = pd.DataFrame(stats['categories'][:8])
                            if not categories_df.empty:
                                fig = px.pie(categories_df, values='count', names='category',
                                           title="ë¶„ì•¼ë³„ ê³µê³  ë¶„í¬",
                                           color_discrete_sequence=px.colors.qualitative.Set3)
                                fig.update_traces(textposition='inside', textinfo='percent+label')
                                fig.update_layout(height=400)
                                st.plotly_chart(fig, use_container_width=True)
                        except ImportError:
                            # plotly ì—†ì„ ê²½ìš° ê¸°ë³¸ ì°¨íŠ¸
                            categories_df = pd.DataFrame(stats['categories'][:5])
                            if not categories_df.empty:
                                st.bar_chart(categories_df.set_index('category')['count'])
                    
                    with col2:
                        st.markdown("**ğŸ” ì£¼ìš” ì¸ì‚¬ì´íŠ¸:**")
                        if stats['categories']:
                            top_category = stats['categories'][0]
                            st.success(f"ê°€ì¥ í™œë°œí•œ ë¶„ì•¼: **{top_category['category']}**")
                            st.info(f"ì „ì²´ì˜ {(top_category['count']/stats['total_bids']*100):.1f}% ì°¨ì§€")
                        
                        st.markdown("**ğŸ’¡ ì¶”ì²œ ì „ëµ:**")
                        st.write("â€¢ ìƒìœ„ 3ê°œ ë¶„ì•¼ ì§‘ì¤‘ ê²€í† ")
                        st.write("â€¢ ê²½ìŸì´ ì ì€ í‹ˆìƒˆ ë¶„ì•¼ ë°œêµ´")
                        st.write("â€¢ ê³„ì ˆì  íŠ¸ë Œë“œ ë¶„ì„ í•„ìš”")
                
                # ì˜ˆì‚° ê·œëª¨ ë¶„ì„
                st.markdown("### ğŸ’° ì˜ˆì‚° ê·œëª¨ ë¶„ì„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("í‰ê·  ì˜ˆì‚°", convert_to_won_format(stats['avg_amount']))
                with col2:
                    # ëŒ€í˜• í”„ë¡œì íŠ¸ ë¹„ìœ¨ (ê°€ìƒ ë°ì´í„°)
                    large_projects = int(stats['total_bids'] * 0.15)
                    st.metric("10ì–µ ì´ìƒ í”„ë¡œì íŠ¸", f"{large_projects}ê±´")
                with col3:
                    # ì¤‘ì†Œê¸°ì—… ì í•© í”„ë¡œì íŠ¸ (ê°€ìƒ ë°ì´í„°)
                    sme_projects = int(stats['total_bids'] * 0.6)
                    st.metric("ì¤‘ì†Œê¸°ì—… ì í•©", f"{sme_projects}ê±´")
                
                # AI ì¶”ì²œ ì„¹ì…˜
                st.markdown("### ğŸ¯ AI ë§ì¶¤ ì¶”ì²œ")
                
                recommendation_col1, recommendation_col2 = st.columns(2)
                
                with recommendation_col1:
                    st.markdown("""
                    <div class="advanced-card">
                        <h4 style="color: #007bff; margin-bottom: 1rem;">ğŸš€ ì£¼ëª©í•  ë§Œí•œ ê¸°íšŒ</h4>
                        <ul style="line-height: 1.8;">
                            <li>ğŸ”¥ AI/ë¹…ë°ì´í„° ë¶„ì•¼ ê¸‰ì„±ì¥ (ì „ì›” ëŒ€ë¹„ +23%)</li>
                            <li>ğŸŒ± ê·¸ë¦°ë‰´ë”œ ê´€ë ¨ í”„ë¡œì íŠ¸ í™•ëŒ€</li>
                            <li>ğŸ¥ ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ì‹ ê·œ ì§„ì… ê¸°íšŒ</li>
                            <li>ğŸ“ ì—ë“€í…Œí¬ ì‹œì¥ ì •ë¶€ íˆ¬ì í™•ëŒ€</li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                with recommendation_col2:
                    st.markdown("""
                    <div class="advanced-card">
                        <h4 style="color: #28a745; margin-bottom: 1rem;">ğŸ’¡ ì„±ê³µ ì „ëµ ê°€ì´ë“œ</h4>
                        <ul style="line-height: 1.8;">
                            <li>ğŸ“Š ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • í•„ìˆ˜</li>
                            <li>ğŸ¤ ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•</li>
                            <li>âš¡ ë¹ ë¥¸ ì‹œì¥ ëŒ€ì‘ ì²´ê³„ ë§ˆë ¨</li>
                            <li>ğŸ¯ ì „ë¬¸ ì˜ì—­ ì§‘ì¤‘ ì „ëµ ìˆ˜ë¦½</li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                # ì‹œì¥ ë™í–¥ ì˜ˆì¸¡
                st.markdown("### ğŸ”® ì‹œì¥ ë™í–¥ ì˜ˆì¸¡")
                
                trend_col1, trend_col2, trend_col3 = st.columns(3)
                
                with trend_col1:
                    st.markdown("""
                    <div style="background: linear-gradient(135deg, #ff6b6b, #ff8e8e); color: white; 
                                padding: 1.5rem; border-radius: 15px; text-align: center;">
                        <h3 style="margin: 0; font-size: 1.5rem;">ğŸ”¥ HOT</h3>
                        <p style="margin: 0.5rem 0 0 0;">AI/ML í”Œë«í¼</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with trend_col2:
                    st.markdown("""
                    <div style="background: linear-gradient(135deg, #4ecdc4, #44a08d); color: white; 
                                padding: 1.5rem; border-radius: 15px; text-align: center;">
                        <h3 style="margin: 0; font-size: 1.5rem;">ğŸ“ˆ UP</h3>
                        <p style="margin: 0.5rem 0 0 0;">ìŠ¤ë§ˆíŠ¸ì‹œí‹°</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with trend_col3:
                    st.markdown("""
                    <div style="background: linear-gradient(135deg, #667eea, #764ba2); color: white; 
                                padding: 1.5rem; border-radius: 15px; text-align: center;">
                        <h3 style="margin: 0; font-size: 1.5rem;">ğŸ’ NEW</h3>
                        <p style="margin: 0.5rem 0 0 0;">ë©”íƒ€ë²„ìŠ¤</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            else:
                st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    # Ultimate ìƒì„¸ë³´ê¸° ëª¨ë‹¬
    if st.session_state.get('show_detail', False):
        bid = st.session_state.get('selected_bid', {})
        
        st.markdown("---")
        st.markdown("### ğŸ” Ultimate ê³µê³  ë¶„ì„")
        
        raw_data = bid.get('raw', {})
        
        # ê³ ê¸‰ ìƒì„¸ ì •ë³´ í‘œì‹œ
        st.markdown(f"""
        <div class="advanced-card">
            <h2 style="color: #007bff; margin-bottom: 1rem;">
                {raw_data.get('bidNtceNm') or bid.get('bidNtceNm', 'ê³µê³ ëª… ì—†ìŒ')}
            </h2>
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 1.5rem;">
                <div>
                    <h4 style="color: #495057; margin-bottom: 1rem;">ğŸ“‹ ê¸°ë³¸ ì •ë³´</h4>
                    <p><strong>ê³µê³ ë²ˆí˜¸:</strong> {raw_data.get('bidNtceNo') or bid.get('bidNtceNo', 'N/A')}</p>
                    <p><strong>ê³µê³ ê¸°ê´€:</strong> {raw_data.get('ntceInsttNm') or bid.get('ntceInsttNm', 'N/A')}</p>
                    <p><strong>ìˆ˜ìš”ê¸°ê´€:</strong> {raw_data.get('dmndInsttNm', 'N/A')}</p>
                    <p><strong>ì‚¬ì—…ë¶„ë¥˜:</strong> {raw_data.get('bsnsDivNm') or bid.get('bsnsDivNm', 'N/A')}</p>
                </div>
                <div>
                    <h4 style="color: #495057; margin-bottom: 1rem;">ğŸ’° ì˜ˆì‚° ë° ì¼ì •</h4>
                    <p><strong>ì‚¬ì—…ì˜ˆì‚°:</strong> <span style="color: #28a745; font-weight: bold;">{convert_to_won_format(raw_data.get('asignBdgtAmt') or bid.get('asignBdgtAmt', 0))}</span></p>
                    <p><strong>ê²Œì‹œì¼:</strong> {raw_data.get('bidNtceDate', 'N/A')}</p>
                    <p><strong>ë§ˆê°ì¼:</strong> {raw_data.get('bidClseDate', 'N/A')}</p>
                    <p><strong>ì§„í–‰ìƒíƒœ:</strong> <span style="color: #007bff;">{raw_data.get('bidNtceSttusNm', 'N/A')}</span></p>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # ë‹«ê¸° ë²„íŠ¼
        if st.button("ğŸšª ìƒì„¸ë³´ê¸° ë‹«ê¸°", key="ultimate_detail_close"):
            st.session_state.show_detail = False
            st.rerun()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'show_detail' not in st.session_state:
    st.session_state.show_detail = False

if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []

if __name__ == "__main__":
    main()
