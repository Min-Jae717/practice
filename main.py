import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import json
import numpy as np
from typing import TypedDict, Annotated, List, Dict, Optional
import operator

# ì„¤ì • íŒŒì¼ import
from config import get_app_config, check_secrets

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì…ì°° ê³µê³  ì„œë¹„ìŠ¤", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    .main-header p {
        font-size: 1.2rem;
        opacity: 0.9;
    }
    .similarity-high { color: #28a745; font-weight: bold; }
    .similarity-medium { color: #ffc107; font-weight: bold; }
    .similarity-low { color: #dc3545; }
    .workflow-step {
        background: #f8f9fa;
        padding: 10px;
        margin: 5px 0;
        border-left: 4px solid #007bff;
        border-radius: 5px;
    }
    .workflow-success {
        background: #d4edda;
        border-left-color: #28a745;
    }
    .workflow-warning {
        background: #fff3cd;
        border-left-color: #ffc107;
    }
</style>
""", unsafe_allow_html=True)

# LangGraph ìƒíƒœ ì •ì˜
class BidSearchState(TypedDict):
    """ì…ì°° ê³µê³  ê²€ìƒ‰ ìƒíƒœ"""
    query: str
    keyword_results: List[Dict]
    semantic_results: List[Dict]
    api_results: List[Dict]
    combined_results: List[Dict]
    final_answer: str
    messages: Annotated[List[str], operator.add]
    error: Optional[str]

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í´ë˜ìŠ¤
class EnhancedBidManager:
    def __init__(self):
        try:
            import psycopg2
            from psycopg2.extras import RealDictCursor
            
            config = get_app_config()
            self.connection = psycopg2.connect(
                config.database.url,
                cursor_factory=RealDictCursor
            )
            self.connection.autocommit = True
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.connection = None
    
    def get_live_bids(self, limit=50):
        """ì‹¤ì‹œê°„ ì…ì°° ê³µê³  ì¡°íšŒ"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw->>'bidNtceDate' as bidNtceDate,
                raw->>'bidClseDate' as bidClseDate,
                raw
            FROM bids_live
            ORDER BY created_at DESC
            LIMIT %s
            """
            cursor.execute(query, (limit,))
            results = cursor.fetchall()
            return [dict(row) for row in results]
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def search_bids(self, keyword):
        """í‚¤ì›Œë“œë¡œ ì…ì°° ê³µê³  ê²€ìƒ‰"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw
            FROM bids_live
            WHERE raw->>'bidNtceNm' ILIKE %s
               OR raw->>'ntceInsttNm' ILIKE %s
               OR raw->>'bidprcPsblIndstrytyNm' ILIKE %s
            ORDER BY created_at DESC
            LIMIT 30
            """
            cursor.execute(query, (f"%{keyword}%", f"%{keyword}%", f"%{keyword}%"))
            results = cursor.fetchall()
            return [dict(row) for row in results]
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ë²¡í„° ê²€ìƒ‰ í´ë˜ìŠ¤
class VectorSearchEngine:
    def __init__(self):
        try:
            from sentence_transformers import SentenceTransformer
            self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            self.is_loaded = True
        except Exception as e:
            st.warning(f"ë²¡í„° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.is_loaded = False
    
    def encode_text(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        if not self.is_loaded:
            return None
        try:
            return self.model.encode([text])[0]
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return None
    
    def calculate_similarity(self, query_vector, doc_vectors):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            from sklearn.metrics.pairwise import cosine_similarity
            similarities = cosine_similarity([query_vector], doc_vectors)[0]
            return similarities
        except Exception as e:
            st.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    
    def semantic_search(self, query, bid_data, top_k=10):
        """ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰"""
        if not self.is_loaded or not bid_data:
            return []
        
        try:
            # ì¿¼ë¦¬ ë²¡í„°í™”
            query_vector = self.encode_text(query)
            if query_vector is None:
                return []
            
            # ë¬¸ì„œ ë²¡í„°í™”
            documents = []
            doc_vectors = []
            
            for bid in bid_data:
                # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ êµ¬ì„±
                text = f"{bid.get('bidntcenm', '')} {bid.get('ntceinsttm', '')} {bid.get('bsnsdivnm', '')}"
                doc_vector = self.encode_text(text)
                
                if doc_vector is not None:
                    documents.append(bid)
                    doc_vectors.append(doc_vector)
            
            if not doc_vectors:
                return []
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = self.calculate_similarity(query_vector, doc_vectors)
            
            # ê²°ê³¼ ì •ë ¬
            results = []
            for i, sim in enumerate(similarities):
                if sim > 0.1:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
                    results.append({
                        'document': documents[i],
                        'similarity': float(sim)
                    })
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x['similarity'], reverse=True)
            return results[:top_k]
            
        except Exception as e:
            st.error(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ë‚˜ë¼ì¥í„° API ê²€ìƒ‰ í´ë˜ìŠ¤
class APISearchEngine:
    def __init__(self):
        try:
            config = get_app_config()
            self.service_key = config.api.service_key
            self.base_url = config.api.base_url
            self.endpoints = {
                "ìš©ì—­": f"{self.base_url}/getBidPblancListInfoServc",
                "ë¬¼í’ˆ": f"{self.base_url}/getBidPblancListInfoThng"
            }
        except Exception as e:
            st.warning(f"API ì„¤ì • ì‹¤íŒ¨: {e}")
            self.service_key = None
    
    def search_api(self, query, limit=10):
        """ë‚˜ë¼ì¥í„° API ê²€ìƒ‰"""
        if not self.service_key:
            return []
        
        try:
            import requests
            from urllib.parse import urlencode
            
            # ìµœê·¼ 30ì¼ ë°ì´í„° ê²€ìƒ‰
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            
            all_results = []
            
            for category, endpoint in self.endpoints.items():
                try:
                    params = {
                        'serviceKey': self.service_key,
                        'pageNo': 1,
                        'numOfRows': limit,
                        'type': 'json',
                        'inqryBgnDt': start_date.strftime('%Y%m%d') + '0000',
                        'inqryEndDt': end_date.strftime('%Y%m%d') + '2359',
                        'bidNtceNm': query
                    }
                    
                    response = requests.get(endpoint, params=params, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        items = data.get('response', {}).get('body', {}).get('items', [])
                        
                        if items:
                            for item in items:
                                item['source'] = f'API({category})'
                            all_results.extend(items)
                
                except Exception as e:
                    continue
            
            return all_results[:limit]
            
        except Exception as e:
            return []

# LangGraph ì›Œí¬í”Œë¡œìš° ë…¸ë“œë“¤
def keyword_search_node(state: BidSearchState) -> BidSearchState:
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        bid_manager = EnhancedBidManager()
        results = bid_manager.search_bids(state["query"])
        
        state["keyword_results"] = results
        state["messages"].append(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´")
        
    except Exception as e:
        state["error"] = f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["keyword_results"] = []
    
    return state

def semantic_search_node(state: BidSearchState) -> BidSearchState:
    """ì‹œë§¨í‹± ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        vector_engine = VectorSearchEngine()
        
        if vector_engine.is_loaded and state["keyword_results"]:
            results = vector_engine.semantic_search(state["query"], state["keyword_results"], top_k=10)
            state["semantic_results"] = results
            state["messages"].append(f"âœ… AI ì‹œë§¨í‹± ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´")
        else:
            state["semantic_results"] = []
            state["messages"].append("âš ï¸ ì‹œë§¨í‹± ê²€ìƒ‰ ë¶ˆê°€ (ëª¨ë¸ ë¯¸ë¡œë“œ ë˜ëŠ” ë°ì´í„° ì—†ìŒ)")
        
    except Exception as e:
        state["error"] = f"ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["semantic_results"] = []
    
    return state

def api_search_node(state: BidSearchState) -> BidSearchState:
    """API ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        api_engine = APISearchEngine()
        
        # ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ë•Œë§Œ API í˜¸ì¶œ
        total_existing = len(state["keyword_results"]) + len(state["semantic_results"])
        
        if total_existing < 5:
            results = api_engine.search_api(state["query"], limit=10)
            state["api_results"] = results
            state["messages"].append(f"âœ… ì‹¤ì‹œê°„ API ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´")
        else:
            state["api_results"] = []
            state["messages"].append("â„¹ï¸ ì¶©ë¶„í•œ ê²€ìƒ‰ ê²°ê³¼ë¡œ API ê²€ìƒ‰ ìƒëµ")
        
    except Exception as e:
        state["error"] = f"API ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        state["api_results"] = []
    
    return state

def combine_results_node(state: BidSearchState) -> BidSearchState:
    """ê²°ê³¼ í†µí•© ë…¸ë“œ"""
    try:
        combined = {}
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for item in state["keyword_results"]:
            bid_no = item.get("bidntceno") or item.get("bidNtceNo")
            if bid_no:
                combined[bid_no] = {
                    **item,
                    "sources": ["í‚¤ì›Œë“œ"],
                    "relevance_score": 3
                }
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€/ë³‘í•©
        for result in state["semantic_results"]:
            item = result["document"]
            bid_no = item.get("bidntceno") or item.get("bidNtceNo")
            if bid_no:
                if bid_no in combined:
                    combined[bid_no]["sources"].append("AIì‹œë§¨í‹±")
                    combined[bid_no]["relevance_score"] += result["similarity"] * 10
                    combined[bid_no]["similarity"] = result["similarity"]
                else:
                    combined[bid_no] = {
                        **item,
                        "sources": ["AIì‹œë§¨í‹±"],
                        "relevance_score": result["similarity"] * 10,
                        "similarity": result["similarity"]
                    }
        
        # API ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for item in state["api_results"]:
            bid_no = item.get("bidNtceNo")
            if bid_no:
                if bid_no in combined:
                    combined[bid_no]["sources"].append("ì‹¤ì‹œê°„API")
                    combined[bid_no]["relevance_score"] += 2
                else:
                    combined[bid_no] = {
                        **item,
                        "sources": ["ì‹¤ì‹œê°„API"],
                        "relevance_score": 2
                    }
        
        # ê´€ë ¨ë„ ìˆœ ì •ë ¬
        combined_list = list(combined.values())
        combined_list.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
        
        state["combined_results"] = combined_list[:15]
        state["messages"].append(f"âœ… ê²°ê³¼ í†µí•© ì™„ë£Œ: {len(state['combined_results'])}ê±´")
        
    except Exception as e:
        state["error"] = f"ê²°ê³¼ í†µí•© ì˜¤ë¥˜: {str(e)}"
        state["combined_results"] = []
    
    return state

def generate_final_answer_node(state: BidSearchState) -> BidSearchState:
    """ìµœì¢… ë‹µë³€ ìƒì„± ë…¸ë“œ"""
    try:
        from langchain_openai import ChatOpenAI
        config = get_app_config()
        
        llm = ChatOpenAI(
            api_key=config.openai.api_key,
            model=config.openai.model,
            temperature=0.7
        )
        
        if not state["combined_results"]:
            state["final_answer"] = f"'{state['query']}'ì— ëŒ€í•œ ì…ì°° ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return state
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "## ê²€ìƒ‰ëœ ì…ì°° ê³µê³  ì •ë³´:\n\n"
        
        for i, result in enumerate(state["combined_results"][:5]):
            sources = ", ".join(result.get("sources", []))
            context += f"**{i+1}. {result.get('bidntcenm') or result.get('bidNtceNm', 'ì œëª©ì—†ìŒ')}**\n"
            context += f"- ê¸°ê´€: {result.get('ntceinsttm') or result.get('ntceInsttNm', 'ê¸°ê´€ì—†ìŒ')}\n"
            context += f"- ë¶„ë¥˜: {result.get('bsnsdivnm') or result.get('bsnsDivNm', 'ë¶„ë¥˜ì—†ìŒ')}\n"
            context += f"- ê²€ìƒ‰ë°©ë²•: {sources}\n"
            if 'similarity' in result:
                context += f"- AI ìœ ì‚¬ë„: {result['similarity']:.1%}\n"
            context += f"- ê´€ë ¨ë„: {result.get('relevance_score', 0):.1f}ì \n\n"
        
        prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {state['query']}

{context}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê³µê³ ë“¤ì„ ìš°ì„  ì†Œê°œ
2. ê° ê³µê³ ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…
3. ì…ì°° ì°¸ì—¬ ì‹œ ê³ ë ¤ì‚¬í•­ ì¡°ì–¸
4. ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ ì•ˆë‚´

3-4ë¬¸ì¥ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        response = llm.invoke(prompt)
        state["final_answer"] = response.content
        state["messages"].append("âœ… AI ë‹µë³€ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        state["error"] = f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}"
        state["final_answer"] = "ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    return state

# LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
@st.cache_resource
def create_workflow():
    """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    try:
        from langgraph.graph import StateGraph, END
        
        workflow = StateGraph(BidSearchState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("keyword_search", keyword_search_node)
        workflow.add_node("semantic_search", semantic_search_node)
        workflow.add_node("api_search", api_search_node)
        workflow.add_node("combine_results", combine_results_node)
        workflow.add_node("generate_answer", generate_final_answer_node)
        
        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("keyword_search")
        workflow.add_edge("keyword_search", "semantic_search")
        workflow.add_edge("semantic_search", "api_search")
        workflow.add_edge("api_search", "combine_results")
        workflow.add_edge("combine_results", "generate_answer")
        workflow.add_edge("generate_answer", END)
        
        return workflow.compile()
    except Exception as e:
        st.error(f"ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# AI ì±—ë´‡ í´ë˜ìŠ¤ (í–¥ìƒëœ ë²„ì „)
class EnhancedAIChatbot:
    def __init__(self):
        try:
            from langchain_openai import ChatOpenAI
            config = get_app_config()
            self.llm = ChatOpenAI(
                api_key=config.openai.api_key,
                model=config.openai.model,
                temperature=0.7
            )
        except Exception as e:
            st.error(f"AI ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
    
    def get_response(self, question: str, search_results: list, semantic_results: list = None) -> str:
        """í–¥ìƒëœ AI ì‘ë‹µ ìƒì„±"""
        if not self.llm:
            return "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "## ê´€ë ¨ ì…ì°° ê³µê³  ì •ë³´:\n\n"
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼
            if search_results:
                context += "### í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼:\n"
                for i, bid in enumerate(search_results[:3]):
                    context += f"{i+1}. **{bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}**\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceinsttm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë¶„ë¥˜: {bid.get('bsnsdivnm', 'ë¶„ë¥˜ì—†ìŒ')}\n\n"
            
            # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼
            if semantic_results:
                context += "### AI ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:\n"
                for i, result in enumerate(semantic_results[:3]):
                    bid = result['document']
                    similarity = result['similarity']
                    context += f"{i+1}. **{bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}** (ìœ ì‚¬ë„: {similarity:.1%})\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceinsttm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë¶„ë¥˜: {bid.get('bsnsdivnm', 'ë¶„ë¥˜ì—†ìŒ')}\n\n"
            
            prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {question}

{context}

ìœ„ ì…ì°° ê³µê³  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê³µê³ ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì„¤ëª…
2. ê° ê³µê³ ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬
3. ì…ì°° ì°¸ì—¬ì‹œ ê³ ë ¤ì‚¬í•­ì´ë‚˜ íŒì´ ìˆë‹¤ë©´ ì¡°ì–¸
4. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ì–´ë–¤ ë¶€ë¶„ì„ ë” í™•ì¸í•´ì•¼ í•˜ëŠ”ì§€ ì•ˆë‚´

ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ, 3-5ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”.
"""
            
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def convert_to_won_format(amount):
    """ê¸ˆì•¡ì„ ì› ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
    try:
        if not amount:
            return "ê³µê³  ì°¸ì¡°"
        
        amount = float(str(amount).replace(",", ""))
        if amount >= 100000000:
            return f"{amount/100000000:.1f}ì–µì›"
        elif amount >= 10000:
            return f"{amount/10000:.1f}ë§Œì›"
        else:
            return f"{int(amount):,}ì›"
    except:
        return "ê³µê³  ì°¸ì¡°"

def format_similarity(similarity):
    """ìœ ì‚¬ë„ í¬ë§·íŒ…"""
    if similarity >= 0.7:
        return f'<span class="similarity-high">{similarity:.1%}</span>'
    elif similarity >= 0.4:
        return f'<span class="similarity-medium">{similarity:.1%}</span>'
    else:
        return f'<span class="similarity-low">{similarity:.1%}</span>'

# ë§¤ë‹ˆì € ì´ˆê¸°í™”
@st.cache_resource
def init_managers():
    check_secrets()
    bid_manager = EnhancedBidManager()
    vector_engine = VectorSearchEngine()
    chatbot = EnhancedAIChatbot()
    workflow = create_workflow()
    return bid_manager, vector_engine, chatbot, workflow

# ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬
def process_question(question: str, chatbot: EnhancedAIChatbot, bid_manager: EnhancedBidManager, vector_engine: VectorSearchEngine):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„± (í–¥ìƒëœ ë²„ì „)"""
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.chat_messages.append({"role": "user", "content": question})
    
    # ì‘ë‹µ ìƒì„±
    with st.spinner("AIê°€ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ê´€ë ¨ ê³µê³ ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_results = bid_manager.search_bids(question)
        
        # ì‹œë§¨í‹± ê²€ìƒ‰
        semantic_results = []
        if vector_engine.is_loaded and keyword_results:
            semantic_results = vector_engine.semantic_search(question, keyword_results, top_k=5)
        
        # AI ì‘ë‹µ ìƒì„±
        response = chatbot.get_response(question, keyword_results, semantic_results)
    
    # ì‘ë‹µ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response)
        
        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        if semantic_results:
            with st.expander("ğŸ” AI ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸"):
                for i, result in enumerate(semantic_results):
                    bid = result['document']
                    similarity = result['similarity']
                    st.markdown(f"**{i+1}. {bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}**")
                    st.markdown(f"ìœ ì‚¬ë„: {format_similarity(similarity)}", unsafe_allow_html=True)
                    st.caption(f"ê¸°ê´€: {bid.get('ntceinsttm', 'N/A')} | ë¶„ë¥˜: {bid.get('bsnsdivnm', 'N/A')}")
                    st.divider()
    
    st.session_state.chat_messages.append({"role": "assistant", "content": response})

# LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í•¨ìˆ˜
def run_langgraph_workflow(query: str, workflow):
    """LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    if not workflow:
        return None, ["âŒ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    try:
        initial_state = {
            "query": query,
            "keyword_results": [],
            "semantic_results": [],
            "api_results": [],
            "combined_results": [],
            "final_answer": "",
            "messages": [],
            "error": None
        }
        
        final_state = workflow.invoke(initial_state)
        return final_state, final_state.get("messages", [])
        
    except Exception as e:
        return None, [f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"]

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš€ AI ì…ì°° ê³µê³  ê²€ìƒ‰ ì„œë¹„ìŠ¤</h1>
        <p>í‚¤ì›Œë“œ + AI ì‹œë§¨í‹± + ì‹¤ì‹œê°„ API + LangGraph ì›Œí¬í”Œë¡œìš°!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    bid_manager, vector_engine, chatbot, workflow = init_managers()
    
    # íƒ­ ìƒì„± (LangGraph íƒ­ ì¶”ê°€)
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“¢ ì‹¤ì‹œê°„ ì…ì°° ê³µê³ ", 
        "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", 
        "ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰", 
        "âš¡ LangGraph ê³ ê¸‰ ê²€ìƒ‰",
        "ğŸ¤– AI ìƒë‹´"
    ])
    
    with tab1:
        st.subheader("ğŸ“¢ ìµœì‹  ì…ì°° ê³µê³ ")
        
        # ë°ì´í„° ë¡œë“œ
        bids = bid_manager.get_live_bids()
        
        if bids:
            st.success(f"ì´ {len(bids)}ê±´ì˜ ê³µê³ ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ í‘œì‹œ
            for i, bid in enumerate(bids):
                with st.container():
                    col1, col2, col3 = st.columns([3, 2, 1])
                    
                    col1.markdown(f"**{bid.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                    col2.write(f"{bid.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | {bid.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                    col3.write(convert_to_won_format(bid.get('asignbdgtamt', 0)))
                    
                    if st.button("ìƒì„¸ë³´ê¸°", key=f"tab1_detail_{i}"):
                        st.session_state.selected_bid = bid
                        st.session_state.show_detail = True
                        st.rerun()
                    
                    st.divider()
        else:
            st.warning("ì…ì°° ê³µê³  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab2:
        st.subheader("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰")
        
        # ê²€ìƒ‰ UI
        keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: AI, ì†Œí”„íŠ¸ì›¨ì–´, ì„œë²„ ë“±")
        
        if st.button("ê²€ìƒ‰", type="primary", key="tab2_keyword_search"):
            if keyword:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    results = bid_manager.search_bids(keyword)
                    
                    if results:
                        st.success(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´")
                        
                        for i, result in enumerate(results):
                            with st.container():
                                col1, col2 = st.columns([3, 1])
                                col1.markdown(f"**{result.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                                col1.caption(f"{result.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | {result.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                                col2.write(convert_to_won_format(result.get('asignbdgtamt', 0)))
                                st.divider()
                    else:
                        st.warning(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.subheader("ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰")
        st.info("ğŸ’¡ AIê°€ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ê´€ë ¨ì„± ë†’ì€ ê³µê³ ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!")
        
        if not vector_engine.is_loaded:
            st.warning("âš ï¸ ë²¡í„° ê²€ìƒ‰ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")
        else:
            # ê²€ìƒ‰ UI
            semantic_query = st.text_input("ìì—°ì–´ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”", 
                                         placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê´€ë ¨ í”„ë¡œì íŠ¸, í´ë¼ìš°ë“œ ì„œë²„ êµ¬ì¶•ì‚¬ì—… ë“±")
            
            col1, col2 = st.columns([1, 4])
            with col1:
                top_k = st.selectbox("ê²°ê³¼ ìˆ˜", [5, 10, 15, 20], index=1)
            
            if st.button("ğŸ¯ AI ê²€ìƒ‰", type="primary", key="tab3_semantic_search"):
                if semantic_query:
                    with st.spinner("AIê°€ ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ê³µê³ ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # ë¨¼ì € í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ í™•ë³´
                        candidates = bid_manager.search_bids(semantic_query)
                        
                        if candidates:
                            # ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰
                            semantic_results = vector_engine.semantic_search(semantic_query, candidates, top_k=top_k)
                            
                            if semantic_results:
                                st.success(f"AIê°€ ì°¾ì€ ê´€ë ¨ ê³µê³ : {len(semantic_results)}ê±´")
                                
                                # ê²°ê³¼ í‘œì‹œ
                                for i, result in enumerate(semantic_results):
                                    bid = result['document']
                                    similarity = result['similarity']
                                    
                                    with st.container():
                                        col1, col2, col3 = st.columns([0.5, 3, 1])
                                        
                                        # ìœ ì‚¬ë„ í‘œì‹œ
                                        col1.markdown(format_similarity(similarity), unsafe_allow_html=True)
                                        
                                        # ê³µê³  ì •ë³´
                                        col2.markdown(f"**{bid.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                                        col2.caption(f"ğŸ¢ {bid.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | ğŸ“ {bid.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                                        
                                        # ê¸ˆì•¡
                                        col3.write(convert_to_won_format(bid.get('asignbdgtamt', 0)))
                                        
                                        st.divider()
                            else:
                                st.warning("ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab4:
        st.subheader("âš¡ LangGraph ê¸°ë°˜ ê³ ê¸‰ ê²€ìƒ‰")
        st.info("ğŸ”¥ AI ì›Œí¬í”Œë¡œìš°ê°€ í‚¤ì›Œë“œ + ì‹œë§¨í‹± + API ê²€ìƒ‰ì„ ìë™ìœ¼ë¡œ ì¡°í•©í•©ë‹ˆë‹¤!")
        
        # ê²€ìƒ‰ UI
        langgraph_query = st.text_input("ê³ ê¸‰ ê²€ìƒ‰ ì§ˆì˜", 
                                       placeholder="ì˜ˆ: AI ê°œë°œ í”„ë¡œì íŠ¸ ì°¾ì•„ì¤˜, ì„œë²„ êµ¬ì¶• ê´€ë ¨ ìµœì‹  ì…ì°°ì€?")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            show_workflow = st.checkbox("ì›Œí¬í”Œë¡œìš° ê³¼ì • í‘œì‹œ", value=True)
        
        if st.button("âš¡ LangGraph ê²€ìƒ‰", type="primary", key="tab4_langgraph_search"):
            if langgraph_query:
                with st.spinner("AI ì›Œí¬í”Œë¡œìš°ê°€ ë‹¤ì¤‘ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    final_state, messages = run_langgraph_workflow(langgraph_query, workflow)
                    
                    if final_state:
                        # ì›Œí¬í”Œë¡œìš° ê³¼ì • í‘œì‹œ
                        if show_workflow and messages:
                            st.markdown("### ğŸ”„ ê²€ìƒ‰ ì›Œí¬í”Œë¡œìš° ê³¼ì •")
                            for msg in messages:
                                if "âœ…" in msg:
                                    st.markdown(f'<div class="workflow-step workflow-success">{msg}</div>', 
                                              unsafe_allow_html=True)
                                elif "âš ï¸" in msg or "â„¹ï¸" in msg:
                                    st.markdown(f'<div class="workflow-step workflow-warning">{msg}</div>', 
                                              unsafe_allow_html=True)
                                else:
                                    st.markdown(f'<div class="workflow-step">{msg}</div>', 
                                              unsafe_allow_html=True)
                        
                        st.markdown("---")
                        
                        # AI ë‹µë³€ í‘œì‹œ
                        if final_state.get("final_answer"):
                            st.markdown("### ğŸ¤– AI ì¢…í•© ë¶„ì„ ê²°ê³¼")
                            st.success(final_state["final_answer"])
                        
                        # í†µí•© ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                        if final_state.get("combined_results"):
                            st.markdown(f"### ğŸ“‹ í†µí•© ê²€ìƒ‰ ê²°ê³¼ ({len(final_state['combined_results'])}ê±´)")
                            
                            for i, result in enumerate(final_state["combined_results"][:10]):
                                with st.container():
                                    col1, col2, col3, col4 = st.columns([0.5, 2.5, 1.5, 1])
                                    
                                    # ìˆœìœ„
                                    col1.markdown(f"**{i+1}**")
                                    
                                    # ê³µê³  ì •ë³´
                                    title = result.get('bidntcenm') or result.get('bidNtceNm', 'ì œëª© ì—†ìŒ')
                                    org = result.get('ntceinsttm') or result.get('ntceInsttNm', 'ê¸°ê´€ëª… ì—†ìŒ')
                                    col2.markdown(f"**{title}**")
                                    col2.caption(f"ğŸ¢ {org}")
                                    
                                    # ê²€ìƒ‰ ì†ŒìŠ¤ ë° ì ìˆ˜
                                    sources = result.get("sources", [])
                                    score = result.get("relevance_score", 0)
                                    col3.write(f"ğŸ·ï¸ {', '.join(sources)}")
                                    col3.caption(f"ê´€ë ¨ë„: {score:.1f}ì ")
                                    
                                    # ê¸ˆì•¡
                                    amount = result.get('asignbdgtamt') or result.get('asignBdgtAmt', 0)
                                    col4.write(convert_to_won_format(amount))
                                    
                                    # ìœ ì‚¬ë„ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                                    if 'similarity' in result:
                                        col4.markdown(f"ìœ ì‚¬ë„: {format_similarity(result['similarity'])}", 
                                                    unsafe_allow_html=True)
                                    
                                    st.divider()
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab5:
        st.subheader("ğŸ¤– AI ì…ì°° ìƒë‹´")
        st.info("ğŸ’¬ AIê°€ í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ëª¨ë‘ í™œìš©í•˜ì—¬ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤!")
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
        st.markdown("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")
        example_questions = [
            "AI ê°œë°œ ê´€ë ¨ ì…ì°° ê³µê³ ê°€ ìˆë‚˜ìš”?",
            "í´ë¼ìš°ë“œ ì„œë²„ êµ¬ì¶• í”„ë¡œì íŠ¸ë¥¼ ì°¾ê³  ìˆì–´ìš”",
            "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì…ì°°ì˜ ìµœê·¼ ë™í–¥ì€?",
            "ë¹…ë°ì´í„° ë¶„ì„ ê´€ë ¨ ê³µê³  ì¶”ì²œí•´ì£¼ì„¸ìš”"
        ]
        
        cols = st.columns(2)
        for idx, question in enumerate(example_questions):
            if cols[idx % 2].button(question, key=f"tab5_example_{idx}"):
                st.session_state.pending_question = question
                st.rerun()
        
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", key="tab5_chat_reset"):
            st.session_state.chat_messages = []
            st.rerun()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []
        
        # ì´ì „ ëŒ€í™” í‘œì‹œ
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
        if hasattr(st.session_state, 'pending_question'):
            question = st.session_state.pending_question
            del st.session_state.pending_question
            process_question(question, chatbot, bid_manager, vector_engine)
            st.rerun()
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì…ì°° ê´€ë ¨ ì§ˆë¬¸ì„ ììœ ë¡­ê²Œ í•´ì£¼ì„¸ìš”"):
            process_question(prompt, chatbot, bid_manager, vector_engine)
    
    # ìƒì„¸ë³´ê¸° ëª¨ë‹¬
    if st.session_state.get('show_detail', False):
        bid = st.session_state.get('selected_bid', {})
        
        st.markdown("---")
        st.subheader("ğŸ“‹ ê³µê³  ìƒì„¸ ì •ë³´")
        
        raw_data = bid.get('raw', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ê³µê³ ë²ˆí˜¸:** {bid.get('bidntceno', 'N/A')}")
            st.write(f"**ê³µê³ ëª…:** {bid.get('bidntcenm', 'N/A')}")
            st.write(f"**ê³µê³ ê¸°ê´€:** {bid.get('ntceinsttm', 'N/A')}")
            st.write(f"**ë¶„ë¥˜:** {bid.get('bsnsdivnm', 'N/A')}")
        
        with col2:
            st.write(f"**ì˜ˆì‚°:** {convert_to_won_format(bid.get('asignbdgtamt', 0))}")
            st.write(f"**ê²Œì‹œì¼:** {raw_data.get('bidNtceDate', 'N/A')}")
            st.write(f"**ë§ˆê°ì¼:** {raw_data.get('bidClseDate', 'N/A')}")
            st.write(f"**ìƒíƒœ:** {raw_data.get('bidNtceSttusNm', 'N/A')}")
        
        if st.button("ë‹«ê¸°", key="detail_close_btn"):
            st.session_state.show_detail = False
            st.rerun()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'show_detail' not in st.session_state:
    st.session_state.show_detail = False

if __name__ == "__main__":
    main()

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í´ë˜ìŠ¤
class EnhancedBidManager:
    def __init__(self):
        try:
            import psycopg2
            from psycopg2.extras import RealDictCursor
            
            config = get_app_config()
            self.connection = psycopg2.connect(
                config.database.url,
                cursor_factory=RealDictCursor
            )
            self.connection.autocommit = True
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.connection = None
    
    def get_live_bids(self, limit=50):
        """ì‹¤ì‹œê°„ ì…ì°° ê³µê³  ì¡°íšŒ"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw->>'bidNtceDate' as bidNtceDate,
                raw->>'bidClseDate' as bidClseDate,
                raw
            FROM bids_live
            ORDER BY created_at DESC
            LIMIT %s
            """
            cursor.execute(query, (limit,))
            results = cursor.fetchall()
            return [dict(row) for row in results]
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def search_bids(self, keyword):
        """í‚¤ì›Œë“œë¡œ ì…ì°° ê³µê³  ê²€ìƒ‰"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            query = """
            SELECT 
                bidNtceNo,
                raw->>'bidNtceNm' as bidNtceNm,
                raw->>'ntceInsttNm' as ntceInsttNm,
                raw->>'bsnsDivNm' as bsnsDivNm,
                raw->>'asignBdgtAmt' as asignBdgtAmt,
                raw
            FROM bids_live
            WHERE raw->>'bidNtceNm' ILIKE %s
               OR raw->>'ntceInsttNm' ILIKE %s
               OR raw->>'bidprcPsblIndstrytyNm' ILIKE %s
            ORDER BY created_at DESC
            LIMIT 30
            """
            cursor.execute(query, (f"%{keyword}%", f"%{keyword}%", f"%{keyword}%"))
            results = cursor.fetchall()
            return [dict(row) for row in results]
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def get_semantic_chunks(self, limit=100):
        """ë²¡í„° ê²€ìƒ‰ìš© ë°ì´í„° ì¡°íšŒ"""
        if not self.connection:
            return []
        
        try:
            cursor = self.connection.cursor()
            query = """
            SELECT 
                sc.content,
                sc.metadata,
                sc.bidNtceNo,
                bl.raw->>'bidNtceNm' as bidNtceNm,
                bl.raw->>'ntceInsttNm' as ntceInsttNm
            FROM semantic_chunks sc
            JOIN bids_live bl ON sc.bidNtceNo = bl.bidNtceNo
            ORDER BY sc.created_at DESC
            LIMIT %s
            """
            cursor.execute(query, (limit,))
            results = cursor.fetchall()
            return [dict(row) for row in results]
        except Exception as e:
            # semantic_chunks í…Œì´ë¸”ì´ ì—†ì„ ê²½ìš° ë¹ˆ ë°°ì—´ ë°˜í™˜
            return []

# ë²¡í„° ê²€ìƒ‰ í´ë˜ìŠ¤
class VectorSearchEngine:
    def __init__(self):
        try:
            from sentence_transformers import SentenceTransformer
            self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            self.is_loaded = True
        except Exception as e:
            st.warning(f"ë²¡í„° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.is_loaded = False
    
    def encode_text(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        if not self.is_loaded:
            return None
        try:
            return self.model.encode([text])[0]
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return None
    
    def calculate_similarity(self, query_vector, doc_vectors):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            from sklearn.metrics.pairwise import cosine_similarity
            similarities = cosine_similarity([query_vector], doc_vectors)[0]
            return similarities
        except Exception as e:
            st.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    
    def semantic_search(self, query, bid_data, top_k=10):
        """ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰"""
        if not self.is_loaded or not bid_data:
            return []
        
        try:
            # ì¿¼ë¦¬ ë²¡í„°í™”
            query_vector = self.encode_text(query)
            if query_vector is None:
                return []
            
            # ë¬¸ì„œ ë²¡í„°í™”
            documents = []
            doc_vectors = []
            
            for bid in bid_data:
                # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ êµ¬ì„±
                text = f"{bid.get('bidntcenm', '')} {bid.get('ntceinsttm', '')} {bid.get('bsnsdivnm', '')}"
                doc_vector = self.encode_text(text)
                
                if doc_vector is not None:
                    documents.append(bid)
                    doc_vectors.append(doc_vector)
            
            if not doc_vectors:
                return []
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = self.calculate_similarity(query_vector, doc_vectors)
            
            # ê²°ê³¼ ì •ë ¬
            results = []
            for i, sim in enumerate(similarities):
                if sim > 0.1:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
                    results.append({
                        'document': documents[i],
                        'similarity': float(sim)
                    })
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x['similarity'], reverse=True)
            return results[:top_k]
            
        except Exception as e:
            st.error(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# AI ì±—ë´‡ í´ë˜ìŠ¤ (í–¥ìƒëœ ë²„ì „)
class EnhancedAIChatbot:
    def __init__(self):
        try:
            from langchain_openai import ChatOpenAI
            config = get_app_config()
            self.llm = ChatOpenAI(
                api_key=config.openai.api_key,
                model=config.openai.model,
                temperature=0.7
            )
        except Exception as e:
            st.error(f"AI ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
    
    def get_response(self, question: str, search_results: list, semantic_results: list = None) -> str:
        """í–¥ìƒëœ AI ì‘ë‹µ ìƒì„±"""
        if not self.llm:
            return "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "## ê´€ë ¨ ì…ì°° ê³µê³  ì •ë³´:\n\n"
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼
            if search_results:
                context += "### í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼:\n"
                for i, bid in enumerate(search_results[:3]):
                    context += f"{i+1}. **{bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}**\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceinsttm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë¶„ë¥˜: {bid.get('bsnsdivnm', 'ë¶„ë¥˜ì—†ìŒ')}\n\n"
            
            # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼
            if semantic_results:
                context += "### AI ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:\n"
                for i, result in enumerate(semantic_results[:3]):
                    bid = result['document']
                    similarity = result['similarity']
                    context += f"{i+1}. **{bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}** (ìœ ì‚¬ë„: {similarity:.1%})\n"
                    context += f"   - ê¸°ê´€: {bid.get('ntceinsttm', 'ê¸°ê´€ì—†ìŒ')}\n"
                    context += f"   - ë¶„ë¥˜: {bid.get('bsnsdivnm', 'ë¶„ë¥˜ì—†ìŒ')}\n\n"
            
            prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {question}

{context}

ìœ„ ì…ì°° ê³µê³  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê³µê³ ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì„¤ëª…
2. ê° ê³µê³ ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬
3. ì…ì°° ì°¸ì—¬ì‹œ ê³ ë ¤ì‚¬í•­ì´ë‚˜ íŒì´ ìˆë‹¤ë©´ ì¡°ì–¸
4. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ì–´ë–¤ ë¶€ë¶„ì„ ë” í™•ì¸í•´ì•¼ í•˜ëŠ”ì§€ ì•ˆë‚´

ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ, 3-5ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”.
"""
            
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def convert_to_won_format(amount):
    """ê¸ˆì•¡ì„ ì› ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
    try:
        if not amount:
            return "ê³µê³  ì°¸ì¡°"
        
        amount = float(str(amount).replace(",", ""))
        if amount >= 100000000:
            return f"{amount/100000000:.1f}ì–µì›"
        elif amount >= 10000:
            return f"{amount/10000:.1f}ë§Œì›"
        else:
            return f"{int(amount):,}ì›"
    except:
        return "ê³µê³  ì°¸ì¡°"

def format_similarity(similarity):
    """ìœ ì‚¬ë„ í¬ë§·íŒ…"""
    if similarity >= 0.7:
        return f'<span class="similarity-high">{similarity:.1%}</span>'
    elif similarity >= 0.4:
        return f'<span class="similarity-medium">{similarity:.1%}</span>'
    else:
        return f'<span class="similarity-low">{similarity:.1%}</span>'

# ë§¤ë‹ˆì € ì´ˆê¸°í™”
@st.cache_resource
def init_managers():
    check_secrets()
    bid_manager = EnhancedBidManager()
    vector_engine = VectorSearchEngine()
    chatbot = EnhancedAIChatbot()
    return bid_manager, vector_engine, chatbot

# ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬
def process_question(question: str, chatbot: EnhancedAIChatbot, bid_manager: EnhancedBidManager, vector_engine: VectorSearchEngine):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„± (í–¥ìƒëœ ë²„ì „)"""
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.chat_messages.append({"role": "user", "content": question})
    
    # ì‘ë‹µ ìƒì„±
    with st.spinner("AIê°€ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ê´€ë ¨ ê³µê³ ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_results = bid_manager.search_bids(question)
        
        # ì‹œë§¨í‹± ê²€ìƒ‰
        semantic_results = []
        if vector_engine.is_loaded and keyword_results:
            semantic_results = vector_engine.semantic_search(question, keyword_results, top_k=5)
        
        # AI ì‘ë‹µ ìƒì„±
        response = chatbot.get_response(question, keyword_results, semantic_results)
    
    # ì‘ë‹µ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response)
        
        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        if semantic_results:
            with st.expander("ğŸ” AI ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸"):
                for i, result in enumerate(semantic_results):
                    bid = result['document']
                    similarity = result['similarity']
                    st.markdown(f"**{i+1}. {bid.get('bidntcenm', 'ì œëª©ì—†ìŒ')}**")
                    st.markdown(f"ìœ ì‚¬ë„: {format_similarity(similarity)}", unsafe_allow_html=True)
                    st.caption(f"ê¸°ê´€: {bid.get('ntceinsttm', 'N/A')} | ë¶„ë¥˜: {bid.get('bsnsdivnm', 'N/A')}")
                    st.divider()
    
    st.session_state.chat_messages.append({"role": "assistant", "content": response})

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš€ AI ì…ì°° ê³µê³  ê²€ìƒ‰ ì„œë¹„ìŠ¤</h1>
        <p>í‚¤ì›Œë“œ ê²€ìƒ‰ + AI ì‹œë§¨í‹± ê²€ìƒ‰ + ì§€ëŠ¥í˜• ìƒë‹´ê¹Œì§€!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    bid_manager, vector_engine, chatbot = init_managers()
    
    # íƒ­ ìƒì„± (AI ê²€ìƒ‰ íƒ­ ì¶”ê°€)
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¢ ì‹¤ì‹œê°„ ì…ì°° ê³µê³ ", "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", "ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰", "ğŸ¤– AI ìƒë‹´"])
    
    with tab1:
        st.subheader("ğŸ“¢ ìµœì‹  ì…ì°° ê³µê³ ")
        
        # ë°ì´í„° ë¡œë“œ
        bids = bid_manager.get_live_bids()
        
        if bids:
            st.success(f"ì´ {len(bids)}ê±´ì˜ ê³µê³ ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ í‘œì‹œ
            for i, bid in enumerate(bids):
                with st.container():
                    col1, col2, col3 = st.columns([3, 2, 1])
                    
                    col1.markdown(f"**{bid.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                    col2.write(f"{bid.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | {bid.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                    col3.write(convert_to_won_format(bid.get('asignbdgtamt', 0)))
                    
                    if st.button("ìƒì„¸ë³´ê¸°", key=f"detail_{i}"):
                        st.session_state.selected_bid = bid
                        st.session_state.show_detail = True
                        st.rerun()
                    
                    st.divider()
        else:
            st.warning("ì…ì°° ê³µê³  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab2:
        st.subheader("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰")
        
        # ê²€ìƒ‰ UI
        keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: AI, ì†Œí”„íŠ¸ì›¨ì–´, ì„œë²„ ë“±")
        
        if st.button("ê²€ìƒ‰", type="primary", key="keyword_search"):
            if keyword:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    results = bid_manager.search_bids(keyword)
                    
                    if results:
                        st.success(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´")
                        
                        for i, result in enumerate(results):
                            with st.container():
                                col1, col2 = st.columns([3, 1])
                                col1.markdown(f"**{result.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                                col1.caption(f"{result.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | {result.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                                col2.write(convert_to_won_format(result.get('asignbdgtamt', 0)))
                                st.divider()
                    else:
                        st.warning(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.subheader("ğŸ¯ AI ì‹œë§¨í‹± ê²€ìƒ‰")
        st.info("ğŸ’¡ AIê°€ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ê´€ë ¨ì„± ë†’ì€ ê³µê³ ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!")
        
        if not vector_engine.is_loaded:
            st.warning("âš ï¸ ë²¡í„° ê²€ìƒ‰ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")
        else:
            # ê²€ìƒ‰ UI
            semantic_query = st.text_input("ìì—°ì–´ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”", 
                                         placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê´€ë ¨ í”„ë¡œì íŠ¸, í´ë¼ìš°ë“œ ì„œë²„ êµ¬ì¶•ì‚¬ì—… ë“±")
            
            col1, col2 = st.columns([1, 4])
            with col1:
                top_k = st.selectbox("ê²°ê³¼ ìˆ˜", [5, 10, 15, 20], index=1)
            
            if st.button("ğŸ¯ AI ê²€ìƒ‰", type="primary", key="semantic_search"):
                if semantic_query:
                    with st.spinner("AIê°€ ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ê³µê³ ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # ë¨¼ì € í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ í™•ë³´
                        candidates = bid_manager.search_bids(semantic_query)
                        
                        if candidates:
                            # ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰
                            semantic_results = vector_engine.semantic_search(semantic_query, candidates, top_k=top_k)
                            
                            if semantic_results:
                                st.success(f"AIê°€ ì°¾ì€ ê´€ë ¨ ê³µê³ : {len(semantic_results)}ê±´")
                                
                                # ê²°ê³¼ í‘œì‹œ
                                for i, result in enumerate(semantic_results):
                                    bid = result['document']
                                    similarity = result['similarity']
                                    
                                    with st.container():
                                        col1, col2, col3 = st.columns([0.5, 3, 1])
                                        
                                        # ìœ ì‚¬ë„ í‘œì‹œ
                                        col1.markdown(format_similarity(similarity), unsafe_allow_html=True)
                                        
                                        # ê³µê³  ì •ë³´
                                        col2.markdown(f"**{bid.get('bidntcenm', 'ì œëª© ì—†ìŒ')}**")
                                        col2.caption(f"ğŸ¢ {bid.get('ntceinsttm', 'ê¸°ê´€ëª… ì—†ìŒ')} | ğŸ“ {bid.get('bsnsdivnm', 'ë¶„ë¥˜ ì—†ìŒ')}")
                                        
                                        # ê¸ˆì•¡
                                        col3.write(convert_to_won_format(bid.get('asignbdgtamt', 0)))
                                        
                                        st.divider()
                            else:
                                st.warning("ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab4:
        st.subheader("ğŸ¤– AI ì…ì°° ìƒë‹´")
        st.info("ğŸ’¬ AIê°€ í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ëª¨ë‘ í™œìš©í•˜ì—¬ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤!")
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
        st.markdown("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")
        example_questions = [
            "AI ê°œë°œ ê´€ë ¨ ì…ì°° ê³µê³ ê°€ ìˆë‚˜ìš”?",
            "í´ë¼ìš°ë“œ ì„œë²„ êµ¬ì¶• í”„ë¡œì íŠ¸ë¥¼ ì°¾ê³  ìˆì–´ìš”",
            "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì…ì°°ì˜ ìµœê·¼ ë™í–¥ì€?",
            "ë¹…ë°ì´í„° ë¶„ì„ ê´€ë ¨ ê³µê³  ì¶”ì²œí•´ì£¼ì„¸ìš”"
        ]
        
        cols = st.columns(2)
        for idx, question in enumerate(example_questions):
            if cols[idx % 2].button(question, key=f"example_{idx}"):
                st.session_state.pending_question = question
                st.rerun()
        
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.chat_messages = []
            st.rerun()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []
        
        # ì´ì „ ëŒ€í™” í‘œì‹œ
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
        if hasattr(st.session_state, 'pending_question'):
            question = st.session_state.pending_question
            del st.session_state.pending_question
            process_question(question, chatbot, bid_manager, vector_engine)
            st.rerun()
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì…ì°° ê´€ë ¨ ì§ˆë¬¸ì„ ììœ ë¡­ê²Œ í•´ì£¼ì„¸ìš”"):
            process_question(prompt, chatbot, bid_manager, vector_engine)
    
    # ìƒì„¸ë³´ê¸° ëª¨ë‹¬
    if st.session_state.get('show_detail', False):
        bid = st.session_state.get('selected_bid', {})
        
        st.markdown("---")
        st.subheader("ğŸ“‹ ê³µê³  ìƒì„¸ ì •ë³´")
        
        raw_data = bid.get('raw', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ê³µê³ ë²ˆí˜¸:** {bid.get('bidntceno', 'N/A')}")
            st.write(f"**ê³µê³ ëª…:** {bid.get('bidntcenm', 'N/A')}")
            st.write(f"**ê³µê³ ê¸°ê´€:** {bid.get('ntceinsttm', 'N/A')}")
            st.write(f"**ë¶„ë¥˜:** {bid.get('bsnsdivnm', 'N/A')}")
        
        with col2:
            st.write(f"**ì˜ˆì‚°:** {convert_to_won_format(bid.get('asignbdgtamt', 0))}")
            st.write(f"**ê²Œì‹œì¼:** {raw_data.get('bidNtceDate', 'N/A')}")
            st.write(f"**ë§ˆê°ì¼:** {raw_data.get('bidClseDate', 'N/A')}")
            st.write(f"**ìƒíƒœ:** {raw_data.get('bidNtceSttusNm', 'N/A')}")
        
        if st.button("ë‹«ê¸°"):
            st.session_state.show_detail = False
            st.rerun()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'show_detail' not in st.session_state:
    st.session_state.show_detail = False

if __name__ == "__main__":
    main()
